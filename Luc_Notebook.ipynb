{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import scipy as sp\n",
    "from time import time\n",
    "from utils.data import load_data, save_results\n",
    "from utils.models import SVM, SPR, PCA\n",
    "from utils.kernels import GaussianKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    " #   writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "  #  writer.writerow([\"Id\", \"Bound\"])\n",
    "   # for i in range(3000):\n",
    "    #    writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR: A Simple Pattern Recognition Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.99875 / 0.585 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.5775 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 5e-5\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "results = np.zeros(3000)\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SPR(kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    #results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Kernels (to delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol_kernel(x,y,c): #c=0\n",
    "    return (x.dot(y) + c)**2\n",
    "\n",
    "def gaussian_kernel(x,y, gamma): #c=100\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y)**2)\n",
    "\n",
    "def linear_kernel(x,y,c): \n",
    "    return x.dot(y)\n",
    "\n",
    "def laplace_kernel(x,y,gamma):\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 5e-05,γ: 400)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 5e-05,γ: 400)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 5e-05,γ: 400)\n"
     ]
    }
   ],
   "source": [
    "γ = 400\n",
    "λ = 5e-5\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "results = np.zeros(3000)\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    #results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 5e-06,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 5e-06,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 5e-06,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 2.875e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 2.875e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 2.875e-05,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 5.25e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 5.25e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 5.25e-05,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 7.625e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 7.625e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 7.625e-05,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 0.0001,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 0.0001,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 0.0001,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 5e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 5e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 5e-06,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 2.875e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 2.875e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 2.875e-05,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 5.25e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 5.25e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 5.25e-05,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 7.625e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 7.625e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 7.625e-05,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 0.0001,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 0.0001,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 0.0001,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 5e-06,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 5e-06,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 5e-06,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 2.875e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 2.875e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 2.875e-05,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 5.25e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 5.25e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 5.25e-05,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 7.625e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 7.625e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 7.625e-05,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 0.0001,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 0.0001,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 0.0001,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5675 (λ: 5e-06,γ: 450.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7325 (λ: 5e-06,γ: 450.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 5e-06,γ: 450.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5675 (λ: 2.875e-05,γ: 450.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7325 (λ: 2.875e-05,γ: 450.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 2.875e-05,γ: 450.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5675 (λ: 5.25e-05,γ: 450.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7325 (λ: 5.25e-05,γ: 450.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 5.25e-05,γ: 450.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5675 (λ: 7.625e-05,γ: 450.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7325 (λ: 7.625e-05,γ: 450.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 7.625e-05,γ: 450.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5675 (λ: 0.0001,γ: 450.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7325 (λ: 0.0001,γ: 450.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 0.0001,γ: 450.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5e-06,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 5e-06,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5e-06,γ: 500.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 2.875e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 2.875e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 2.875e-05,γ: 500.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5.25e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 5.25e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5.25e-05,γ: 500.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 7.625e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 7.625e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 7.625e-05,γ: 500.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 0.0001,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 0.0001,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 0.0001,γ: 500.0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 1e-4\n",
    "gamma_list = np.linspace(300,γ,5, endpoint = True)\n",
    "lambda_list = np.linspace(5e-6, λ, 5, endpoint = True)\n",
    "settings = list(product(gamma_list,lambda_list))\n",
    "best_score = {i: 0 for i in range(3)}\n",
    "best_lambda = {i: 0 for i in range(3)}\n",
    "best_gamma = {i: 0 for i in range(3)}\n",
    "\n",
    "for k, tup in enumerate(settings):\n",
    "    \n",
    "    γ, λ = tup\n",
    "    \n",
    "    kernel = GaussianKernel(γ)\n",
    "\n",
    "    results = np.zeros(3000)\n",
    "    len_files = len(FILES)\n",
    "    for i in range(len_files):\n",
    "        X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "        X_val = X_train[1600:]\n",
    "        Y_val = Y_train[1600:]\n",
    "        X_train = X_train[:1600]\n",
    "        Y_train = Y_train[:1600]\n",
    "        clf = SVM(_lambda=λ, kernel=kernel)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_pred_train =clf.predict(X_train)\n",
    "        y_pred_val = clf.predict(X_val)\n",
    "        score_train = clf.score(y_pred_train, Y_train)\n",
    "        score_val = clf.score(y_pred_val, Y_val)\n",
    "        #results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "        print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1er lancement:\n",
    "- score : {0: 0.6, 1: 0.6775, 2: 0.6425}\n",
    "- lambda : {0: 0.0002575, 1: 1e-05, 2: 0.000505}\n",
    "- gamma : {0: 77.5, 1: 100.0, 2: 32.5}\n",
    "\n",
    "2ème lancement:\n",
    "- score : {0: 0.61, 1: 0.7075, 2: 0.6425}\n",
    "- lambda : {0: 5.5e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 70.0, 1: 300.0, 2: 300.0}\n",
    "\n",
    "3ème lancement:\n",
    "- score : {0: 0.6075, 1: 0.73, 2: 0.66}\n",
    "- lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 350.0, 1: 400.0, 2: 500.0}\n",
    "\n",
    "4ème lancement:\n",
    "- score : {0: 0.59, 1: 0.73, 2: 0.6575}\n",
    "- lambda : {0: 5e-06, 1: 5e-06, 2: 5e-06}\n",
    "- gamma : {0: 400.0, 1: 400.0, 2: 400.0}\n",
    "\n",
    "5ème lancement ! :\n",
    "- score : {0: 0.59, 1: 0.73, 2: 0.6575}\n",
    "- lambda : {0: 5e-05, 1: 5e-05, 2: 5e-05}\n",
    "- gamma : {0: 400.0, 1: 400.0, 2: 400.0}\n",
    "\n",
    "6ème lancement (après shuffle):\n",
    "- score : {0: 0.5775, 1: 0.745, 2: 0.6375}\n",
    "- lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 400.0, 1: 300.0, 2: 500.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological Sequence Modeling with Convolutional Kernel Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to encode k-mer of x centered at position i**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = {'A': [1.,0.,0.,0.],\n",
    "                'C': [0.,1.,0.,0.],\n",
    "                'G': [0.,0.,1.,0.],\n",
    "                'T': [0.,0.,0.,1.]\n",
    "               }\n",
    "\n",
    "def P(i, x, k):\n",
    "    \n",
    "    not_in = True # True when the k-mers computed is at the edge of the sequence x\n",
    "    if i-(k+1)//2 + 1 < 0:\n",
    "        k_mer_i = x[len(x) + i-(k+1)//2 + 1:] + x[0 :  i + (k+2)//2]\n",
    "    elif i + (k+2)//2 > len(x):\n",
    "        k_mer_i = x[i-(k+1)//2 + 1 : ] +  x[:i + (k+2)//2 - len(x)]\n",
    "    else:\n",
    "        k_mer_i = x[i-(k+1)//2 + 1 :  i + (k+2)//2]\n",
    "        not_in = False\n",
    "        \n",
    "    # concatenate one hot encoding\n",
    "    L = []\n",
    "    for c in k_mer_i:\n",
    "        L += ENCODING[c]\n",
    "    \n",
    "    return np.array(L), not_in\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Kernels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(u, σ):\n",
    "    return np.exp((u-1)/σ**2)\n",
    "\n",
    "# define the kernel on k-mers with the norm\n",
    "def K0(z1, z2, σ):\n",
    "    z1_norm = np.linalg.norm(z1)\n",
    "    z2_norm = np.linalg.norm(z2)\n",
    "    z1z2_norm = z1_norm*z2_norm\n",
    "    return z1z2_norm*np.exp(-(1/(2*z1z2_norm*(σ**2)))*np.linalg.norm(z1-z2)**2)\n",
    "\n",
    "# same kernel but with the scalar product\n",
    "def K1(z1, z2, σ):\n",
    "    z1_norm = np.linalg.norm(z1)\n",
    "    z2_norm = np.linalg.norm(z2)\n",
    "    z1z2_norm = z1_norm*z2_norm\n",
    "    u = z1.dot(z2)/z1z2_norm\n",
    "    return z1z2_norm*K(u,σ)\n",
    "\n",
    "# define the kernel on sequences of k-mers\n",
    "def conv_kernel(x,y,k, σ):\n",
    "    mx = len(x)\n",
    "    my = len(y)    \n",
    "    Px = np.array([P(i,x,k)[0] for i in range(mx)])\n",
    "    Py = np.array([P(i,y,k)[0] for i in range(mx)])\n",
    "    PxPyt = Px.dot(Py.T)/k\n",
    "    s = k*np.exp((1/(σ**2))*(PxPyt-1))\n",
    "        \n",
    "    return np.sum(s)/(mx*my)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning of the anchor points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose parameters k of k-mer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load all the k-mers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of k-mers : 188000\n"
     ]
    }
   ],
   "source": [
    "def compute_kmers_list(idx, k):\n",
    "    \n",
    "    \n",
    "    \"\"\"This function compute all the k-mers of a list of sequences\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    - idx : int\n",
    "        index of the dataset (0,1, or 2)\n",
    "    - k : int\n",
    "        length of the k-mers\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, Y_train, X_test = load_data(idx, mat = False)\n",
    "    n = len(X_train)\n",
    "    m = len(X_train[0])\n",
    "    \n",
    "    kmers = []\n",
    "    for x in X_train:\n",
    "        for i in range(m):\n",
    "            p = P(i,x,k)\n",
    "            if p[1] == False:\n",
    "                kmers.append(p[0])\n",
    "            \n",
    "    kmers = np.array(kmers)\n",
    "    \n",
    "    return kmers\n",
    "\n",
    "idx= 0\n",
    "kmers = compute_kmers_list(idx, k)\n",
    "\n",
    "print(f\"Number of k-mers : {len(kmers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test some $\\sigma$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ0 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the kernel on k-mers:\n",
      "- Value of the kernel with two identical k-mer as input\n",
      "8.000000000000002 8.000000000000002 8.000000000000002 8.000000000000002\n",
      "- Value of the kernel with two random different k-mer as input\n",
      "0.767736688359989 0.1609263522139273 0.03373199591672751 0.1609263522139273\n",
      "\n",
      " Check the kernel on sequences:\n",
      "- Value of the kernel with two identical sequences as input\n",
      "0.21254973750129444\n",
      "0.21895625843245542\n",
      "0.20113939892968546\n",
      "0.2091916795102786\n",
      "0.21922818727797896\n",
      "- Value of the kernel with two random different sequences as input\n",
      "0.14117079276869135\n",
      "0.12154697253293836\n",
      "0.12570274766640196\n",
      "0.13376932811992803\n",
      "0.14601150641540067\n"
     ]
    }
   ],
   "source": [
    "print(\"Check the kernel on k-mers:\")\n",
    "\n",
    "print('- Value of the kernel with two identical k-mer as input')\n",
    "print(K0(kmers[0],kmers[0], σ0 ), K0(kmers[1000],kmers[1000],σ0), K0(kmers[2000],kmers[2000],σ0), \n",
    "      K0(kmers[3000],kmers[3000],σ0))\n",
    "\n",
    "print('- Value of the kernel with two random different k-mer as input')\n",
    "print(K0(kmers[0],kmers[1],σ0), K0(kmers[1000],kmers[1],σ0), K0(kmers[2000],kmers[1],σ0), K0(kmers[3000],kmers[1],σ0))\n",
    "\n",
    "print(\"\\n Check the kernel on sequences:\")\n",
    "print('- Value of the kernel with two identical sequences as input')\n",
    "print(conv_kernel(X_train[10],X_train[10],k, σ0))\n",
    "print(conv_kernel(X_train[100],X_train[100],k, σ0))\n",
    "print(conv_kernel(X_train[1000],X_train[1000],k, σ0))\n",
    "print(conv_kernel(X_train[1100],X_train[1100],k, σ0))\n",
    "print(conv_kernel(X_train[1200],X_train[1200],k, σ0))\n",
    "\n",
    "print('- Value of the kernel with two random different sequences as input')\n",
    "print(conv_kernel(X_train[0],X_train[10],k, σ0))\n",
    "print(conv_kernel(X_train[10],X_train[100],k, σ0))\n",
    "print(conv_kernel(X_train[100],X_train[1000],k, σ0))\n",
    "print(conv_kernel(X_train[1000],X_train[1100],k, σ0))\n",
    "print(conv_kernel(X_train[1100],X_train[1200],k, σ0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X, K, max_iter):\n",
    "    \n",
    "    #step 0 (initialize centroids mu)\n",
    "    idx = np.random.randint(len(X), size=K)\n",
    "    mu = X[idx]    \n",
    "    \n",
    "    n_iter = 0\n",
    "    stop = False\n",
    "    d = 1e6\n",
    "    while stop != True:\n",
    "        \n",
    "        #create clusters\n",
    "        clustering = np.zeros(len(X))\n",
    "            \n",
    "        #step 1 (minimizing by assigning a cluster to each point)\n",
    "        for i in range(len(X)):\n",
    "            clustering[i] = np.argmin(np.linalg.norm(X[i]-mu, axis=1))\n",
    "\n",
    "        \n",
    "        #step 2 (minimizing w.r.t mu)\n",
    "        for k in range(K):\n",
    "            if np.sum([clustering==k]) != 0:\n",
    "                mu[k] = np.mean(X[clustering==k], axis=0)\n",
    "\n",
    "        \n",
    "        d_new = distortion(X, mu, clustering)\n",
    "        #print(d_new)\n",
    "        \n",
    "        if(d_new == d) or n_iter > max_iter:\n",
    "            stop = True\n",
    "        d = d_new\n",
    "        n_iter +=1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return mu, clustering\n",
    "\n",
    "\n",
    "def distortion(X, mu, clustering):\n",
    "    dis = 0\n",
    "    for k in range(len(mu)):\n",
    "        dis = dis + np.linalg.norm(X[clustering==k] - mu[k])**2\n",
    "    return dis\n",
    "\n",
    "#We try several random initializations and keep the partition which minimize the distorsion.\n",
    "def Kmeans_try(X, n_try, n_cluster, max_iter):\n",
    "\n",
    "    for i in range(n_try):\n",
    "        \n",
    "        mu, cl = Kmeans(X, n_cluster, max_iter)\n",
    "    \n",
    "        if i == 0:\n",
    "            dist_min = distortion(X, mu, cl)\n",
    "            mu_min, cl_min = mu, cl\n",
    "        else:\n",
    "            if distortion(X, mu, cl) < dist_min:\n",
    "                dist_min = distortion(X, mu, cl)\n",
    "                mu_min, cl_min = mu, cl\n",
    "                \n",
    "                \n",
    "    return mu_min, cl_min, dist_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "σc = 0.4\n",
    "\n",
    "def spec_cl(n_cl, kmers, σ):\n",
    "    \n",
    "    # compute Gram matrix\n",
    "    n = len(kmers)\n",
    "    K = np.zeros((n,n))\n",
    "    for j in range(n):\n",
    "        for i in range(j+1):\n",
    "            K[i,j] = K1(kmers[i],kmers[j], σ)\n",
    "    K =  K + K.T\n",
    "    np.fill_diagonal(K, np.diagonal(K)/2)\n",
    "     \n",
    "    # Compute the n_cl first eigenvectors (ui, ∆i)\n",
    "    λ, v = np.linalg.eig(K)\n",
    "    \n",
    "    # compute the maximum entry of a row\n",
    "    #cluster_idx = np.argmax(v[:,:n_cl], axis = 1)\n",
    "    # Kmeans on the rows\n",
    "    t = time()\n",
    "    n_try = 1\n",
    "    max_iter = 10\n",
    "    Z = v[:,:n_cl]/np.sum(v[:,:n_cl],axis=1).reshape(-1,1) # normalize v\n",
    "    \n",
    "    mu_rows, cluster_idx, dist = Kmeans_try(Z, n_try, n_cl, max_iter)\n",
    "    print(f\"time kmeans {time() - t}\")\n",
    "    \n",
    "    \n",
    "    # compute the barycenter\n",
    "    mu = []\n",
    "    for i in range(n_cl):\n",
    "        if np.sum([cluster_idx==i]) != 0:\n",
    "            bary = np.mean(kmers[cluster_idx==i], axis = 0)\n",
    "            mu.append(bary)\n",
    "    \n",
    "    return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time kmeans 70.56571865081787\n"
     ]
    }
   ],
   "source": [
    "kmers = compute_kmers_list(0, k)\n",
    "\n",
    "n_cl = 200\n",
    "n_kmers = 10000\n",
    "# choose random kmers to do clustering\n",
    "idx = np.random.choice(range(len(kmers)), size = n_kmers, replace = False)\n",
    "mu = spec_cl(n_cl, kmers[idx], σc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the mapping approximation $\\psi$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ = σc # CHOOSE σ\n",
    "\n",
    "Z = np.einsum('ij, i -> ij',mu, 1/np.linalg.norm(mu, axis = 1)) # normalized mu\n",
    "#Z = skm.cluster_centers_\n",
    "\n",
    "# compute K_ZZ\n",
    "p = len(mu)\n",
    "K_zz = np.zeros((p,p))\n",
    "for j in range(p):\n",
    "    for i in range(j+1):\n",
    "        K_zz[i,j] = K1(Z[i],Z[j], σ)\n",
    "K_zz =  K_zz + K_zz.T\n",
    "np.fill_diagonal(K_zz, np.diagonal(K_zz)/2)\n",
    "\n",
    "# compute K_ZZ\n",
    "K_ZZ_inv_sqr = sp.linalg.sqrtm(np.linalg.inv(K_zz))\n",
    "\n",
    "\n",
    "# define ψ_0\n",
    "def ψ_0(z,Z_anchor, k , σ):\n",
    "    return(K_ZZ_inv_sqr.dot(np.array([K1(z,z_a, σ) for z_a in Z_anchor])))\n",
    "\n",
    "\n",
    "# define ψ\n",
    "def ψ(x, Z_anchor, k , σ):\n",
    "    P_x = [P(i,x,k)[0] for i in range(len(x))]\n",
    "    L = np.array([ψ_0(z, Z_anchor, k, σ) for z in P_x])\n",
    "    return np.sum(L, axis=0)/len(L)\n",
    "\n",
    "\n",
    "# define approx kernel\n",
    "def approx_K(x,y, mu_min, k, σ):\n",
    "    return ψ(x, mu_min, k, σ).dot(ψ(y, mu_min, k, σ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Kernel approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3407923585817665, 8.000000000000002)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.choice(X_train)\n",
    "P_x = [P(i,x,k)[0] for i in range(len(x))]\n",
    "L = np.array([ψ_0(z, Z, k, σ) for z in P_x])\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "L[i].dot(L[j]).real, K0(P_x[i],P_x[j], σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4b0df835a74fc68ad18e1dfca66ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14683165633167428 0.1107116281053657\n",
      "0.11404195571396235 0.09275053903806452\n",
      "0.1299456728132509 0.10126179742647565\n",
      "0.13181622855248343 0.09731325062242525\n",
      "0.12463780799674704 0.09808174431850729\n",
      "0.1171851664923253 0.09186276076921118\n",
      "0.10104907710755105 0.08643515223319374\n",
      "0.11973521486884964 0.09739951668152044\n",
      "0.129817189913863 0.10171397423552414\n",
      "0.11804395761365552 0.09394728021713458\n",
      "% error =  223.25920998951761\n",
      "Mean Approximation Error: 0.026162628375694004 / True Kernel sd : 0.011718499038369967 / Mean true Kernel Value : 0.12331039274043624\n"
     ]
    }
   ],
   "source": [
    "n_mean = 10\n",
    "\n",
    "mu = Z\n",
    "\n",
    "mean_error = 0\n",
    "mean_value = 0\n",
    "var = 0\n",
    "for i in tqdm_notebook(range(n_mean)):\n",
    "    x = np.random.choice(X_train)\n",
    "    y = np.random.choice(X_train)\n",
    "\n",
    "    true_value = conv_kernel(x,y,k, σ)\n",
    "    approx_value = approx_K(x, y, mu, k, σ)\n",
    "    \n",
    "    mean_error += np.abs(true_value - approx_value)\n",
    "    mean_value += true_value\n",
    "    var += true_value**2\n",
    "    \n",
    "    if (i<10):\n",
    "        print(true_value, approx_value)\n",
    "    \n",
    "mean_error = mean_error/n_mean\n",
    "mean_value = mean_value/n_mean\n",
    "var = var/n_mean- mean_value**2\n",
    "standard_deviation = np.sqrt(var)    \n",
    "\n",
    "print(f\"% error =  {mean_error/standard_deviation*100}\")\n",
    "print(f\"Mean Approximation Error: {mean_error} / True Kernel sd : {standard_deviation} / Mean true Kernel Value : {mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute embeddings and Gram matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89a71cf9f3d40ecac1fcca0e00e462a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5937952f2ce4b27b7b9535a59bc2f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "X_train, Y_train, X_test = load_data(i, mat = False)\n",
    "X_val = X_train[1600:]\n",
    "Y_val = Y_train[1600:]\n",
    "X_train = X_train[:1600]\n",
    "Y_train = Y_train[:1600]\n",
    "\n",
    "\n",
    "embed_train = []\n",
    "for x in tqdm_notebook(X_train):\n",
    "    embed_train.append(ψ(x,mu,k,σ))\n",
    "embed_val = []\n",
    "for x in tqdm_notebook(X_val):\n",
    "    embed_val.append(ψ(x,mu,k,σ))\n",
    "    \n",
    "E_train = np.array(embed_train)\n",
    "E_val = np.array(embed_val)\n",
    "    \n",
    "# centering ?\n",
    "centering = False\n",
    "if centering == True:\n",
    "    E_train = E_train - np.mean(E_train)\n",
    "    E_val = E_val - np.mean(E_train)\n",
    "        \n",
    "# compute Gram matrix\n",
    "#K = E_train.dot(E_train.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run SVM!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbd845371cb4383843fdc02a865f1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ae15c50d0c49dca73b2c7b9ab1f5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.905625 / 0.635 (λ: 1e-05,γ: 20)\n"
     ]
    }
   ],
   "source": [
    "kernel = gaussian_kernel\n",
    "γ = 20\n",
    "λ = 1e-5\n",
    "#kernel = linear_kernel\n",
    "\n",
    "\n",
    "clf = SVM(γ, λ, kernel)\n",
    "clf.fit(E_train, Y_train)\n",
    "y_pred_train =clf.predict(E_train)\n",
    "y_pred_val =clf.predict(E_val)\n",
    "score_train = clf.score(y_pred_train, Y_train)\n",
    "score_val = clf.score(y_pred_val, Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85086056c7d4b029a4480088f770687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ce5e9080d643b4a7c5ba9cd75a0e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 1 : 1.0 / 0.6175 (λ: 20,γ: 2000)\n"
     ]
    }
   ],
   "source": [
    "kernel = gaussian_kernel\n",
    "γ = 2000\n",
    "λ = 20\n",
    "#kernel = linear_kernel\n",
    "\n",
    "\n",
    "clf = SVM(γ, λ, kernel)\n",
    "clf.fit(E_train, Y_train)\n",
    "y_pred_train =clf.predict(E_train)\n",
    "y_pred_val =clf.predict(E_val)\n",
    "score_train = clf.score(y_pred_train, Y_train)\n",
    "score_val = clf.score(y_pred_val, Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b07ef9139fa467199954f20bd8b2f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb66a78ea464241acfd33f8ceabbb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 2 : 1.0 / 0.6475 (λ: 1,γ: 1720)\n"
     ]
    }
   ],
   "source": [
    "kernel = gaussian_kernel\n",
    "γ = 1720\n",
    "λ = 1\n",
    "#kernel = linear_kernel\n",
    "\n",
    "\n",
    "clf = SVM(γ, λ, kernel)\n",
    "clf.fit(E_train, Y_train)\n",
    "y_pred_train =clf.predict(E_train)\n",
    "y_pred_val =clf.predict(E_val)\n",
    "score_train = clf.score(y_pred_train, Y_train)\n",
    "score_val = clf.score(y_pred_val, Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.9325 / 0.6575 (λ: 2e-05,γ: 33.8)\n"
     ]
    }
   ],
   "source": [
    "γ = 33.8\n",
    "λ = 2e-5\n",
    "\n",
    "gamma_list = np.linspace(33.8,γ,1, endpoint = True)\n",
    "lambda_list = np.linspace(2e-5, λ, 1, endpoint = True)\n",
    "settings = list(product(gamma_list,lambda_list))\n",
    "\n",
    "\n",
    "for j, tup in enumerate(settings):\n",
    "    \n",
    "    γ, λ = tup\n",
    "    \n",
    "    kernel = GaussianKernel(γ)\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    clf.fit(E_train, Y_train)\n",
    "    y_pred_train =clf.predict(E_train)\n",
    "    y_pred_val =clf.predict(E_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results):\n",
    "    \"\"\"\n",
    "    Save results in a csv file\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    - filename : string\n",
    "        Name of the file to be saved under the ``results`` folder\n",
    "        \n",
    "    - results : numpy.array\n",
    "        Resulting array (0 and 1's)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert filename.endswith(\".csv\"), \"this is not a csv extension!\"\n",
    "    # Convert results to int\n",
    "    results = results.astype(\"int\")\n",
    "    \n",
    "    with open(os.path.join(RESULT_DIR, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write header\n",
    "        writer.writerow([\"Id\", \"Bound\"]) \n",
    "        assert len(results) == 3000, \"There is not 3000 predictions\"\n",
    "        # Write results\n",
    "        for i in range(len(results)):\n",
    "            writer.writerow([i, results[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"results5.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
