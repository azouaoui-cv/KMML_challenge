{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    " #   writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "  #  writer.writerow([\"Id\", \"Bound\"])\n",
    "   # for i in range(3000):\n",
    "    #    writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR: A Simple Pattern Recognition Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPR:\n",
    "    \"\"\"\n",
    "    This class implements the Simple Pattern Recognition algorithm found in the Learning with Kernel books\n",
    "    \"\"\"\n",
    "    def __init__(self,c, kernel=False):\n",
    "        self.m0 = 0\n",
    "        self.m1 = 0\n",
    "        self.b = 0\n",
    "        self.c = c\n",
    "        self.kernel = kernel\n",
    "\n",
    "\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        Fitting phase\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        - X : numpy.ndarray\n",
    "            Data matrix\n",
    "            \n",
    "        - y : numpy.array\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.X0 = X[y == 0]\n",
    "        self.X1 = X[y == 1]\n",
    "        \n",
    "        self.m0 = len(self.X0)\n",
    "        self.m1 = len(self.X1)\n",
    "        \n",
    "        if self.kernel == False:\n",
    "            self.b = 1/2 * (1/(self.m0**2)*np.sum(self.X0.dot(self.X0.T)) - 1/(self.m1**2)*np.sum(self.X1.dot(self.X1.T)))\n",
    "        else:\n",
    "            # à changer\n",
    "            self.list0 = list(np.where(y==0)[0])\n",
    "            self.list1 = list(np.where(y==1)[0])\n",
    "            self.b = 1/2 * (1/(self.m0**2)*np.sum([self.kernel(self.X_train[i],self.X_train[j],self.c) for i in self.list0 for j in self.list0]) - (1/(self.m1**2))*np.sum([self.kernel(self.X_train[i],self.X_train[j],self.c) for i in self.list1 for j in self.list1]))\n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_pred = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if self.kernel == False:\n",
    "                val = 1 / self.m1 * np.sum(self.X1.dot(X[i])) - 1 / self.m0 * np.sum(self.X0.dot(X[i])) + self.b\n",
    "            else:\n",
    "                val = (1/self.m1*np.sum([kernel(self.X_train[k],X[i],self.c) for k in self.list1]) \n",
    "                       - 1/self.m0*np.sum([kernel(self.X_train[k],X[i],self.c) for k in self.list0])) + self.b\n",
    "            y_pred[i] = np.sign(val)/2 + 1/2\n",
    "        return y_pred    \n",
    "    \n",
    "    \n",
    "    def score(self, y, y_pred):\n",
    "        return np.sum([y == y_pred]) / len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_id, mat=True):\n",
    "    \n",
    "    X_train = list()\n",
    "    Y_train = list()\n",
    "    X_test = list()\n",
    "    \n",
    "    dic = FILES[file_id]\n",
    "    \n",
    "    if mat:\n",
    "        files = [dic[\"train_mat\"], dic[\"label\"], dic[\"test_mat\"]]\n",
    "    else:\n",
    "        files = [dic[\"train\"], dic[\"label\"], dic[\"test\"]]\n",
    "\n",
    "    for file, l in zip(files, [X_train, Y_train, X_test]):\n",
    "        with open(os.path.join(DATA_DIR, file), \"r\", newline=\"\") as csvfile:\n",
    "            if \"Y\" in file:\n",
    "                reader = csv.reader(csvfile, delimiter=\",\")\n",
    "                next(reader, None) # Skip the header\n",
    "                for row in reader:\n",
    "                    l.append(row[1])\n",
    "            else:\n",
    "                reader = csv.reader(csvfile, delimiter=\" \")\n",
    "                for row in reader:\n",
    "                    l.append(row)\n",
    "                \n",
    "    X_train = np.array(X_train).astype(\"float\")\n",
    "    Y_train = np.array(Y_train).astype(\"int\")\n",
    "    X_test = np.array(X_test).astype(\"float\")\n",
    "    \n",
    "    return X_train, Y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(x,y,c): #c=0\n",
    "    return (x.dot(y) + c)**2\n",
    "\n",
    "def kernel(x,y, gamma): #c=100\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.563125 / 0.5175\n",
      "Accuracy on train set / val set 1 : 0.65125 / 0.605\n",
      "Accuracy on train set / val set 2 : 0.58625 / 0.6325\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SPR(0, False)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Produit scalaire:**\n",
    "- Accuracy on train set / val set 0 : 0.563125 / 0.5175\n",
    "- Accuracy on train set / val set 1 : 0.65125 / 0.605\n",
    "- Accuracy on train set / val set 2 : 0.58625 / 0.6325\n",
    "\n",
    "**Noyau carré (<.,.>²):**\n",
    "\n",
    "\n",
    "**Noyau Gaussien:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 2 : 0.5735 / nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luc_b\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "len_val = 0\n",
    "len_train = n - len_val\n",
    "all_X_train = np.zeros((3*len_train,100))\n",
    "all_Y_train = np.zeros(3*len_train)\n",
    "all_X_val = np.zeros((3*len_val,100))\n",
    "all_Y_val = np.zeros(3*len_val)\n",
    "all_X_test = np.zeros((3000,100))\n",
    "\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[len_train:]\n",
    "    Y_val = Y_train[len_train:]\n",
    "    X_train = X_train[:len_train]\n",
    "    Y_train = Y_train[:len_train]\n",
    "    all_X_train[i*len_train:i*len_train + len_train] = X_train\n",
    "    all_Y_train[i*len_train:i*len_train + len_train] = Y_train\n",
    "    all_X_val[i*len_val:i*len_val + len_val] = X_val\n",
    "    all_Y_val[i*len_val:i*len_val + len_val] = Y_val\n",
    "    all_X_test[i*1000:i*1000 + 1000] = X_test\n",
    "    \n",
    "clf = SPR(50, False)\n",
    "clf.fit(all_X_train, all_Y_train)\n",
    "y_pred_train =clf.predict(all_X_train)\n",
    "y_pred_val = clf.predict(all_X_val)\n",
    "y_pred_test = clf.predict(all_X_test)\n",
    "score_train = clf.score(y_pred_train, all_Y_train)\n",
    "score_val = clf.score(y_pred_val, all_Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Produit scalaire:**\n",
    "- Accuracy on train set / val set 2 : 0.5741666666666667 / 0.5716666666666667\n",
    "\n",
    "\n",
    "**Noyau carré (<.,.>²):**\n",
    "  - Accuracy on train set / val set 2 : 0.5741666666666667 / 0.5716666666666667 $(c=0)$\n",
    "  \n",
    "**Noyau Gaussien:**\n",
    "- Accuracy on train set / val set 2 : 0.6504166666666666 / 0.57 $(\\gamma = 100)$\n",
    "- Accuracy on train set / val set 2 : 0.5702083333333333 / 0.5691666666666667 $(\\gamma = 10)$\n",
    "- Accuracy on train set / val set 2 : 0.5889583333333334 / 0.5725 $(\\gamma = 50)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results):\n",
    "    \"\"\"\n",
    "    Save results in a csv file\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    - filename : string\n",
    "        Name of the file to be saved under the ``results`` folder\n",
    "        \n",
    "    - results : numpy.array\n",
    "        Resulting array (0 and 1's)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert filename.endswith(\".csv\"), \"this is not a csv extension!\"\n",
    "    # Convert results to int\n",
    "    results = results.astype(\"int\")\n",
    "    \n",
    "    with open(os.path.join(RESULT_DIR, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write header\n",
    "        writer.writerow([\"Id\", \"Bound\"]) \n",
    "        assert len(results) == 3000, \"There is not 3000 predictions\"\n",
    "        # Write results\n",
    "        for i in range(len(results)):\n",
    "            writer.writerow([i, results[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"results3.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
