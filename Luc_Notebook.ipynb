{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import scipy as sp\n",
    "from time import time\n",
    "from utils.data import load_data, save_results\n",
    "from utils.models import SVM, SPR, PCA\n",
    "from utils.kernels import GaussianKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    " #   writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "  #  writer.writerow([\"Id\", \"Bound\"])\n",
    "   # for i in range(3000):\n",
    "    #    writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR: A Simple Pattern Recognition Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.963125 / 0.58 (γ: 284.7)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.755 (γ: 284.7)\n",
      "Accuracy on train set / val set 2 : 0.99625 / 0.6025 (γ: 284.7)\n"
     ]
    }
   ],
   "source": [
    "γ = 284.7\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "results = np.zeros(3000)\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SPR(kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    #results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Kernels (to delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol_kernel(x,y,c): #c=0\n",
    "    return (x.dot(y) + c)**2\n",
    "\n",
    "def gaussian_kernel(x,y, gamma): #c=100\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y)**2)\n",
    "\n",
    "def linear_kernel(x,y,c): \n",
    "    return x.dot(y)\n",
    "\n",
    "def laplace_kernel(x,y,gamma):\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 6e-06,γ: 275)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 6e-06,γ: 275)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 6e-06,γ: 275)\n"
     ]
    }
   ],
   "source": [
    "γ = 275\n",
    "λ = 6e-6\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "results = np.zeros(3000)\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    #results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.5825 (λ: 5e-07,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5e-07,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6175 (λ: 5e-07,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5825 (λ: 2.875e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 2.875e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6175 (λ: 2.875e-06,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5825 (λ: 5.2500000000000006e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5.2500000000000006e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6175 (λ: 5.2500000000000006e-06,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5825 (λ: 7.625000000000001e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 7.625000000000001e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6175 (λ: 7.625000000000001e-06,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5825 (λ: 1e-05,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 1e-05,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6175 (λ: 1e-05,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5e-07,γ: 125.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.6975 (λ: 5e-07,γ: 125.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5e-07,γ: 125.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 2.875e-06,γ: 125.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.6975 (λ: 2.875e-06,γ: 125.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 2.875e-06,γ: 125.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5.2500000000000006e-06,γ: 125.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.6975 (λ: 5.2500000000000006e-06,γ: 125.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5.2500000000000006e-06,γ: 125.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 7.625000000000001e-06,γ: 125.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.6975 (λ: 7.625000000000001e-06,γ: 125.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 7.625000000000001e-06,γ: 125.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 1e-05,γ: 125.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.6975 (λ: 1e-05,γ: 125.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 1e-05,γ: 125.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.58 (λ: 5e-07,γ: 200.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.73 (λ: 5e-07,γ: 200.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5e-07,γ: 200.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.58 (λ: 2.875e-06,γ: 200.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.73 (λ: 2.875e-06,γ: 200.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 2.875e-06,γ: 200.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.58 (λ: 5.2500000000000006e-06,γ: 200.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.73 (λ: 5.2500000000000006e-06,γ: 200.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5.2500000000000006e-06,γ: 200.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.58 (λ: 7.625000000000001e-06,γ: 200.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.73 (λ: 7.625000000000001e-06,γ: 200.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 7.625000000000001e-06,γ: 200.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.58 (λ: 1e-05,γ: 200.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.73 (λ: 1e-05,γ: 200.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 1e-05,γ: 200.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 5e-07,γ: 275.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 5e-07,γ: 275.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 5e-07,γ: 275.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 2.875e-06,γ: 275.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 2.875e-06,γ: 275.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 2.875e-06,γ: 275.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 5.2500000000000006e-06,γ: 275.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 5.2500000000000006e-06,γ: 275.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 5.2500000000000006e-06,γ: 275.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 7.625000000000001e-06,γ: 275.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 7.625000000000001e-06,γ: 275.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 7.625000000000001e-06,γ: 275.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 1e-05,γ: 275.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 1e-05,γ: 275.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 1e-05,γ: 275.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 5e-07,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 5e-07,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 5e-07,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 2.875e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 2.875e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 2.875e-06,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 5.2500000000000006e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 5.2500000000000006e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 5.2500000000000006e-06,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 7.625000000000001e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 7.625000000000001e-06,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 7.625000000000001e-06,γ: 350.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.565 (λ: 1e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.74 (λ: 1e-05,γ: 350.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.63 (λ: 1e-05,γ: 350.0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "γ = 350\n",
    "λ = 1e-5\n",
    "gamma_list = np.linspace(50,γ,5, endpoint = True)\n",
    "lambda_list = np.linspace(5e-7, λ, 5, endpoint = True)\n",
    "settings = list(product(gamma_list,lambda_list))\n",
    "best_score = {i: 0 for i in range(3)}\n",
    "best_lambda = {i: 0 for i in range(3)}\n",
    "best_gamma = {i: 0 for i in range(3)}\n",
    "\n",
    "for k, tup in enumerate(settings):\n",
    "    \n",
    "    γ, λ = tup\n",
    "    kernel = GaussianKernel(γ)\n",
    "\n",
    "    results = np.zeros(3000)\n",
    "    len_files = len(FILES)\n",
    "    for i in range(len_files):\n",
    "        X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "        X_val = X_train[1600:]\n",
    "        Y_val = Y_train[1600:]\n",
    "        X_train = X_train[:1600]\n",
    "        Y_train = Y_train[:1600]\n",
    "        clf = SVM(_lambda=λ, kernel=kernel)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_pred_train =clf.predict(X_train)\n",
    "        y_pred_val = clf.predict(X_val)\n",
    "        score_train = clf.score(y_pred_train, Y_train)\n",
    "        score_val = clf.score(y_pred_val, Y_val)\n",
    "        #results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "        print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")\n",
    "        \n",
    "        if score_val > best_score[i]:\n",
    "            best_score[i] = score_val\n",
    "            best_lambda[i] = λ\n",
    "            best_gamma[i] = γ\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Result:\n",
    "\n",
    "**SVM:**\n",
    "- score : {0: 0.6075, 1: 0.73, 2: 0.66}\n",
    "- lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 350.0, 1: 400.0, 2: 500.0}\n",
    "___\n",
    "- score : {0: 0.5775, 1: 0.745, 2: 0.6375}\n",
    "- lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 400.0, 1: 300.0, 2: 500.0}\n",
    "___\n",
    "- Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 6e-06,γ: 275)\n",
    "- Accuracy on train set / val set 1 : 1.0 / 0.75 (λ: 6e-06,γ: 275)\n",
    "- Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 6e-06,γ: 275)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biological Sequence Modeling with Convolutional Kernel Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to encode k-mer of x centered at position i**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = {'A': [1.,0.,0.,0.],\n",
    "                'C': [0.,1.,0.,0.],\n",
    "                'G': [0.,0.,1.,0.],\n",
    "                'T': [0.,0.,0.,1.]\n",
    "               }\n",
    "\n",
    "def P(i, x, k):\n",
    "    \n",
    "    not_in = True # True when the k-mers computed is at the edge of the sequence x\n",
    "    if i-(k+1)//2 + 1 < 0:\n",
    "        k_mer_i = x[len(x) + i-(k+1)//2 + 1:] + x[0 :  i + (k+2)//2]\n",
    "    elif i + (k+2)//2 > len(x):\n",
    "        k_mer_i = x[i-(k+1)//2 + 1 : ] +  x[:i + (k+2)//2 - len(x)]\n",
    "    else:\n",
    "        k_mer_i = x[i-(k+1)//2 + 1 :  i + (k+2)//2]\n",
    "        not_in = False\n",
    "        \n",
    "    # concatenate one hot encoding\n",
    "    L = []\n",
    "    for c in k_mer_i:\n",
    "        L += ENCODING[c]\n",
    "    \n",
    "    return np.array(L), not_in\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Kernels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def κ(u, σ):\n",
    "    return np.exp((u-1)/σ**2)\n",
    "\n",
    "# define the kernel on k-mers with the norm\n",
    "def K0(z1, z2, σ):\n",
    "    z1_norm = np.linalg.norm(z1)\n",
    "    z2_norm = np.linalg.norm(z2)\n",
    "    z1z2_norm = z1_norm*z2_norm\n",
    "    return z1z2_norm*np.exp(-(1/(2*z1z2_norm*(σ**2)))*np.linalg.norm(z1-z2)**2)\n",
    "\n",
    "# same kernel but with the scalar product\n",
    "def K1(z1, z2, σ):\n",
    "    z1_norm = np.linalg.norm(z1)\n",
    "    z2_norm = np.linalg.norm(z2)\n",
    "    z1z2_norm = z1_norm*z2_norm\n",
    "    u = z1.dot(z2)/z1z2_norm\n",
    "    return z1z2_norm*κ(u,σ)\n",
    "\n",
    "# define the kernel on sequences of k-mers\n",
    "def conv_kernel(x,y,k, σ):\n",
    "    mx = len(x)\n",
    "    my = len(y)    \n",
    "    Px = np.array([P(i,x,k)[0] for i in range(mx)])\n",
    "    Py = np.array([P(i,y,k)[0] for i in range(mx)])\n",
    "    PxPyt = Px.dot(Py.T)/k\n",
    "    s = k*np.exp((1/(σ**2))*(PxPyt-1))\n",
    "        \n",
    "    return np.sum(s)/(mx*my)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning of the anchor points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose parameters k of k-mer here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load all the k-mers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of k-mers : 184000\n"
     ]
    }
   ],
   "source": [
    "def compute_kmers_list(idx, k):\n",
    "    \n",
    "    \n",
    "    \"\"\"This function compute all the k-mers of a list of sequences\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    - idx : int\n",
    "        index of the dataset (0,1, or 2)\n",
    "    - k : int\n",
    "        length of the k-mers\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, Y_train, X_test = load_data(idx, data_dir=DATA_DIR, files_dict=FILES, mat = False)\n",
    "    n = len(X_train)\n",
    "    m = len(X_train[0])\n",
    "    \n",
    "    kmers = []\n",
    "    for x in X_train:\n",
    "        for i in range(m):\n",
    "            p = P(i,x,k)\n",
    "            if p[1] == False:\n",
    "                kmers.append(p[0])\n",
    "            \n",
    "    kmers = np.array(kmers)\n",
    "    \n",
    "    return kmers\n",
    "\n",
    "idx= 0\n",
    "kmers = compute_kmers_list(idx, k)\n",
    "\n",
    "print(f\"Number of k-mers : {len(kmers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test some $\\sigma$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ0 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the kernel on k-mers:\n",
      "- Value of the kernel with two identical k-mer as input\n",
      "10.000000000000002 10.000000000000002 10.000000000000002 10.000000000000002\n",
      "- Value of the kernel with two random different k-mer as input\n",
      "1.3533528323661272 0.9071795328941261 0.27323722447292614 0.18315638888734181\n",
      "\n",
      " Check the kernel on sequences:\n",
      "- Value of the kernel with two identical sequences as input\n",
      "0.7430299942499192\n",
      "0.6850815844240578\n",
      "0.6764297119950851\n",
      "0.6759185994225397\n",
      "0.6880836898524763\n",
      "- Value of the kernel with two random different sequences as input\n",
      "0.5992635129538568\n",
      "0.5893049828335117\n",
      "0.584269544897717\n",
      "0.5901203540677565\n",
      "0.5800125014633629\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, X_test = load_data(0, data_dir=DATA_DIR, files_dict=FILES, mat = False)\n",
    "\n",
    "\n",
    "print(\"Check the kernel on k-mers:\")\n",
    "\n",
    "print('- Value of the kernel with two identical k-mer as input')\n",
    "print(K0(kmers[0],kmers[0], σ0 ), K0(kmers[1000],kmers[1000],σ0), K0(kmers[2000],kmers[2000],σ0), \n",
    "      K0(kmers[3000],kmers[3000],σ0))\n",
    "\n",
    "print('- Value of the kernel with two random different k-mer as input')\n",
    "print(K0(kmers[0],kmers[1],σ0), K0(kmers[1000],kmers[1],σ0), K0(kmers[2000],kmers[1],σ0), K0(kmers[3000],kmers[1],σ0))\n",
    "\n",
    "print(\"\\n Check the kernel on sequences:\")\n",
    "print('- Value of the kernel with two identical sequences as input')\n",
    "print(conv_kernel(X_train[10],X_train[10],k, σ0))\n",
    "print(conv_kernel(X_train[100],X_train[100],k, σ0))\n",
    "print(conv_kernel(X_train[1000],X_train[1000],k, σ0))\n",
    "print(conv_kernel(X_train[1100],X_train[1100],k, σ0))\n",
    "print(conv_kernel(X_train[1200],X_train[1200],k, σ0))\n",
    "\n",
    "print('- Value of the kernel with two random different sequences as input')\n",
    "print(conv_kernel(X_train[0],X_train[10],k, σ0))\n",
    "print(conv_kernel(X_train[10],X_train[100],k, σ0))\n",
    "print(conv_kernel(X_train[100],X_train[1000],k, σ0))\n",
    "print(conv_kernel(X_train[1000],X_train[1100],k, σ0))\n",
    "print(conv_kernel(X_train[1100],X_train[1200],k, σ0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmeans(X, K, max_iter, tol=1e-8):\n",
    "    \n",
    "    #step 0 (initialize centroids mu)\n",
    "    idx = np.random.randint(len(X), size=K)\n",
    "    mu = X[idx]    \n",
    "    \n",
    "    n_iter = 0\n",
    "    stop = False\n",
    "    d = 1e6\n",
    "    while stop != True:\n",
    "        \n",
    "        #create clusters\n",
    "        clustering = np.zeros(len(X))\n",
    "            \n",
    "        #step 1 (minimizing by assigning a cluster to each point)\n",
    "        for i in range(len(X)):\n",
    "            clustering[i] = np.argmin(np.linalg.norm(X[i]-mu, axis=1))\n",
    "\n",
    "        \n",
    "        #step 2 (minimizing w.r.t mu)\n",
    "        for k in range(K):\n",
    "            if np.sum([clustering==k]) != 0:\n",
    "                mu[k] = np.mean(X[clustering==k], axis=0)\n",
    "\n",
    "        \n",
    "        d_new = distortion(X, mu, clustering)\n",
    "        #print(d_new)\n",
    "        \n",
    "        if np.abs(d_new-d) < tol or n_iter > max_iter:\n",
    "            stop = True\n",
    "            \n",
    "        d = d_new\n",
    "        \n",
    "        n_iter +=1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return mu, clustering\n",
    "\n",
    "\n",
    "def distortion(X, mu, clustering):\n",
    "    dis = 0\n",
    "    for k in range(len(mu)):\n",
    "        dis = dis + np.linalg.norm(X[clustering==k] - mu[k])**2\n",
    "    return dis\n",
    "\n",
    "#We try several random initializations and keep the partition which minimize the distorsion.\n",
    "def Kmeans_try(X, n_try, n_cluster, max_iter):\n",
    "\n",
    "    for i in range(n_try):\n",
    "        \n",
    "        mu, cl = Kmeans(X, n_cluster, max_iter)\n",
    "    \n",
    "        if i == 0:\n",
    "            dist_min = distortion(X, mu, cl)\n",
    "            mu_min, cl_min = mu, cl\n",
    "        else:\n",
    "            if distortion(X, mu, cl) < dist_min:\n",
    "                dist_min = distortion(X, mu, cl)\n",
    "                mu_min, cl_min = mu, cl\n",
    "                \n",
    "                \n",
    "    return mu_min, cl_min, dist_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_cl(n_cl, kmers, σ):\n",
    "    \n",
    "    \n",
    "    t = time()\n",
    "\n",
    "    # compute Gram matrix\n",
    "    k = int(len(kmers[0])/4)\n",
    "    kernel = GaussianKernel(1/(2*(σ**2)*k))\n",
    "    K = k*kernel.compute_gram_matrix(kmers)\n",
    "    \n",
    "    print(f\"Time to compute K : {time()-t}\")\n",
    "    t= time()\n",
    "    \n",
    "    # Compute the n_cl first eigenvectors (ui, ∆i)\n",
    "    λ, v = np.linalg.eigh(K)\n",
    "    \n",
    "    print(f\"Time to compute eigenvalues : {time()-t}\")\n",
    "    t=time()\n",
    "    \n",
    "    # compute the maximum entry of a row\n",
    "    #cluster_idx = np.argmax(v[:,:n_cl], axis = 1)\n",
    "    # OR Kmeans on the rows\n",
    "    n_try = 1\n",
    "    max_iter = 20\n",
    "    Z = v[:,:n_cl]/np.linalg.norm(v[:,:n_cl],axis=1).reshape(-1,1) # normalize v\n",
    "    \n",
    "    mu_rows, cluster_idx, dist = Kmeans_try(Z, n_try, n_cl, max_iter)\n",
    "    print(f\"Time to compute kmeans {time() - t}\")\n",
    "    \n",
    "    \n",
    "    # compute the barycenter\n",
    "    mu = []\n",
    "    for i in range(n_cl):\n",
    "        if np.sum([cluster_idx==i]) != 0:\n",
    "            bary = np.mean(kmers[cluster_idx==i], axis = 0)\n",
    "            mu.append(bary)\n",
    "    \n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose parameter $\\sigma$ here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "σc = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute K : 10.33933973312378\n",
      "Time to compute eigenvalues : 335.2367515563965\n",
      "Time to compute kmeans 22.859734296798706\n"
     ]
    }
   ],
   "source": [
    "kmers = compute_kmers_list(0, k)\n",
    "\n",
    "n_cl = 200\n",
    "n_kmers = 10000\n",
    "# choose random kmers to do clustering\n",
    "idx = np.random.choice(range(len(kmers)), size = n_kmers, replace = False)\n",
    "# do spectral clustering\n",
    "mu = spec_cl(n_cl, kmers[idx], σc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the mapping approximation $\\psi$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "σ = σc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute K_ZZ\n",
    "Z = mu\n",
    "p = len(mu)\n",
    "K_zz = np.zeros((p,p))\n",
    "for j in range(p):\n",
    "    for i in range(j+1):\n",
    "        K_zz[i,j] = K1(Z[i],Z[j], σ)\n",
    "K_zz =  K_zz + K_zz.T\n",
    "np.fill_diagonal(K_zz, np.diagonal(K_zz)/2)\n",
    "\n",
    "# compute K_ZZ inv**0.5\n",
    "K_ZZ_inv_sqr = sp.linalg.sqrtm(np.linalg.inv(K_zz))\n",
    "\n",
    "\n",
    "\n",
    "# define ψ_0\n",
    "def ψ_0(z,Z_anchor, k , σ):\n",
    "    return(K_ZZ_inv_sqr.dot(np.array([K1(z,z_a, σ) for z_a in Z_anchor])))\n",
    "\n",
    "\n",
    "# define ψ\n",
    "def ψ(x, Z_anchor, k , σ):\n",
    "    P_x = [P(i,x,k)[0] for i in range(len(x)) if P(i,x,k)[1] == False]\n",
    "    L = np.array([ψ_0(z, Z_anchor, k, σ) for z in P_x])\n",
    "    return np.sum(L, axis=0)/len(L)\n",
    "\n",
    "\n",
    "def ψ_optim(x, Z_anchor, k , σ):\n",
    "    P_x = np.array([P(i,x,k)[0] for i in range(len(x)) if P(i,x,k)[1] == False])\n",
    "    Z = np.array(mu)\n",
    "    Z = Z/np.linalg.norm(Z,axis=1).reshape(-1,1) # normalize Z rows\n",
    "    P_x_norm = P_x/np.linalg.norm(P_x,axis=1).reshape(-1,1) # normalize P_x rows\n",
    "    S = Z.dot(P_x_norm.T)\n",
    "    S = np.einsum('i, ij -> ij',np.linalg.norm(mu,axis=1), np.sqrt(k)*np.exp((S - 1)/σ**2))\n",
    "    b = K_ZZ_inv_sqr.dot(S)\n",
    "    return np.sum(b, axis=1)/np.shape(b)[1]\n",
    "\n",
    "\n",
    "# define approx kernel\n",
    "def approx_K(x,y, mu_min, k, σ):\n",
    "    return ψ(x, mu_min, k, σ).dot(ψ(y, mu_min, k, σ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Kernel approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approximate value : 1.4175094528546452 / true value : 10.000000000000002\n"
     ]
    }
   ],
   "source": [
    "x = np.random.choice(X_train)\n",
    "P_x = [P(i,x,k)[0] for i in range(len(x))]\n",
    "L = np.array([ψ_0(z, Z, k, σ) for z in P_x])\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "print(f\"approximate value : {L[i].dot(L[j]).real} / true value : {K0(P_x[i],P_x[j], σ)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddef08c8d3f40019992b7b62cd086e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5919286902176514 0.4153920371719489\n",
      "0.5800563488576055 0.41537026626247553\n",
      "0.5856734331897614 0.4328333378005927\n",
      "0.5776218422686538 0.43591111471489663\n",
      "0.5503841546628343 0.4105462092257538\n",
      "0.5647625686736343 0.409197544036094\n",
      "0.6632242855075753 0.4925348104454234\n",
      "0.6182443310289063 0.4491945765885702\n",
      "0.693025063482261 0.4967718812672208\n",
      "0.5828641792501127 0.4151328676171765\n",
      "\n",
      "% error =  383.8202168691744\n",
      "Mean Approximation Error: 0.16349002520088435 / True Kernel sd : 0.04259546996624467 / Mean true Kernel Value : 0.6007784897138995\n"
     ]
    }
   ],
   "source": [
    "n_mean = 10\n",
    "\n",
    "mu = Z\n",
    "\n",
    "mean_error = 0\n",
    "mean_value = 0\n",
    "var = 0\n",
    "for i in tqdm_notebook(range(n_mean)):\n",
    "    x = np.random.choice(X_train)\n",
    "    y = np.random.choice(X_train)\n",
    "\n",
    "    true_value = conv_kernel(x,y,k, σ)\n",
    "    approx_value = approx_K(x, y, mu, k, σ)\n",
    "    \n",
    "    mean_error += np.abs(true_value - approx_value)\n",
    "    mean_value += true_value\n",
    "    var += true_value**2\n",
    "    \n",
    "    if (i<10):\n",
    "        print(true_value, approx_value)\n",
    "    \n",
    "mean_error = mean_error/n_mean\n",
    "mean_value = mean_value/n_mean\n",
    "var = var/n_mean- mean_value**2\n",
    "standard_deviation = np.sqrt(var)    \n",
    "\n",
    "print(f\"% error =  {mean_error/standard_deviation*100}\")\n",
    "print(f\"Mean Approximation Error: {mean_error} / True Kernel sd : {standard_deviation} / Mean true Kernel Value : {mean_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute embeddings and Gram matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94605108ae464eae9a118deeaaff363c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b050f7873c54de498680d97e283a34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES, mat = False)\n",
    "X_val = X_train[1600:]\n",
    "Y_val = Y_train[1600:]\n",
    "X_train = X_train[:1600]\n",
    "Y_train = Y_train[:1600]\n",
    "\n",
    "\n",
    "embed_train = []\n",
    "for x in tqdm_notebook(X_train):\n",
    "    embed_train.append(ψ_optim(x,mu,k,σ))\n",
    "embed_val = []\n",
    "for x in tqdm_notebook(X_val):\n",
    "    embed_val.append(ψ_optim(x,mu,k,σ))\n",
    "    \n",
    "E_train = np.array(embed_train)\n",
    "E_val = np.array(embed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run SVM!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.750625 / 0.61 (λ: 1.8e-05,γ: 8.689655172413794)\n"
     ]
    }
   ],
   "source": [
    "γ =  8.689655172413794\n",
    "kernel = GaussianKernel(γ)\n",
    "λ = 1.8e-05\n",
    "#kernel = linear_kernel\n",
    "\n",
    "\n",
    "clf = SVM(λ, kernel)\n",
    "clf.fit(E_train, Y_train)\n",
    "y_pred_train =clf.predict(E_train)\n",
    "y_pred_val =clf.predict(E_val)\n",
    "score_train = clf.score(y_pred_train, Y_train)\n",
    "score_val = clf.score(y_pred_val, Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85086056c7d4b029a4480088f770687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ce5e9080d643b4a7c5ba9cd75a0e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 1 : 1.0 / 0.6175 (λ: 20,γ: 2000)\n"
     ]
    }
   ],
   "source": [
    "kernel = gaussian_kernel\n",
    "γ = 2000\n",
    "λ = 20\n",
    "#kernel = linear_kernel\n",
    "\n",
    "\n",
    "clf = SVM(γ, λ, kernel)\n",
    "clf.fit(E_train, Y_train)\n",
    "y_pred_train =clf.predict(E_train)\n",
    "y_pred_val =clf.predict(E_val)\n",
    "score_train = clf.score(y_pred_train, Y_train)\n",
    "score_val = clf.score(y_pred_val, Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b07ef9139fa467199954f20bd8b2f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb66a78ea464241acfd33f8ceabbb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 2 : 1.0 / 0.6475 (λ: 1,γ: 1720)\n"
     ]
    }
   ],
   "source": [
    "kernel = gaussian_kernel\n",
    "γ = 1720\n",
    "λ = 1\n",
    "#kernel = linear_kernel\n",
    "\n",
    "\n",
    "clf = SVM(γ, λ, kernel)\n",
    "clf.fit(E_train, Y_train)\n",
    "y_pred_train =clf.predict(E_train)\n",
    "y_pred_val =clf.predict(E_val)\n",
    "score_train = clf.score(y_pred_train, Y_train)\n",
    "score_val = clf.score(y_pred_val, Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 1e-08,γ: 3.0)\n",
      "Accuracy on train set / val set 0 : 0.560625 / 0.5 (λ: 0.000200008,γ: 3.0)\n",
      "Accuracy on train set / val set 0 : 0.52875 / 0.4825 (λ: 0.000400006,γ: 3.0)\n",
      "Accuracy on train set / val set 0 : 0.52125 / 0.475 (λ: 0.000600004,γ: 3.0)\n",
      "Accuracy on train set / val set 0 : 0.518125 / 0.4825 (λ: 0.0008000020000000001,γ: 3.0)\n",
      "Accuracy on train set / val set 0 : 0.518125 / 0.485 (λ: 0.001,γ: 3.0)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.58 (λ: 1e-08,γ: 24.88888888888889)\n",
      "Accuracy on train set / val set 0 : 0.71375 / 0.5925 (λ: 0.000200008,γ: 24.88888888888889)\n",
      "Accuracy on train set / val set 0 : 0.67875 / 0.59 (λ: 0.000400006,γ: 24.88888888888889)\n",
      "Accuracy on train set / val set 0 : 0.65375 / 0.575 (λ: 0.000600004,γ: 24.88888888888889)\n",
      "Accuracy on train set / val set 0 : 0.628125 / 0.5425 (λ: 0.0008000020000000001,γ: 24.88888888888889)\n",
      "Accuracy on train set / val set 0 : 0.616875 / 0.525 (λ: 0.001,γ: 24.88888888888889)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5825 (λ: 1e-08,γ: 46.77777777777778)\n",
      "Accuracy on train set / val set 0 : 0.77375 / 0.59 (λ: 0.000200008,γ: 46.77777777777778)\n",
      "Accuracy on train set / val set 0 : 0.72125 / 0.5825 (λ: 0.000400006,γ: 46.77777777777778)\n",
      "Accuracy on train set / val set 0 : 0.6975 / 0.565 (λ: 0.000600004,γ: 46.77777777777778)\n",
      "Accuracy on train set / val set 0 : 0.6775 / 0.5675 (λ: 0.0008000020000000001,γ: 46.77777777777778)\n",
      "Accuracy on train set / val set 0 : 0.6575 / 0.555 (λ: 0.001,γ: 46.77777777777778)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5525 (λ: 1e-08,γ: 68.66666666666667)\n",
      "Accuracy on train set / val set 0 : 0.83625 / 0.5925 (λ: 0.000200008,γ: 68.66666666666667)\n",
      "Accuracy on train set / val set 0 : 0.754375 / 0.57 (λ: 0.000400006,γ: 68.66666666666667)\n",
      "Accuracy on train set / val set 0 : 0.71625 / 0.57 (λ: 0.000600004,γ: 68.66666666666667)\n",
      "Accuracy on train set / val set 0 : 0.6975 / 0.5575 (λ: 0.0008000020000000001,γ: 68.66666666666667)\n",
      "Accuracy on train set / val set 0 : 0.68375 / 0.5575 (λ: 0.001,γ: 68.66666666666667)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.56 (λ: 1e-08,γ: 90.55555555555556)\n",
      "Accuracy on train set / val set 0 : 0.880625 / 0.5825 (λ: 0.000200008,γ: 90.55555555555556)\n",
      "Accuracy on train set / val set 0 : 0.784375 / 0.5725 (λ: 0.000400006,γ: 90.55555555555556)\n",
      "Accuracy on train set / val set 0 : 0.735625 / 0.58 (λ: 0.000600004,γ: 90.55555555555556)\n",
      "Accuracy on train set / val set 0 : 0.710625 / 0.5825 (λ: 0.0008000020000000001,γ: 90.55555555555556)\n",
      "Accuracy on train set / val set 0 : 0.700625 / 0.56 (λ: 0.001,γ: 90.55555555555556)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.55 (λ: 1e-08,γ: 112.44444444444444)\n",
      "Accuracy on train set / val set 0 : 0.928125 / 0.59 (λ: 0.000200008,γ: 112.44444444444444)\n",
      "Accuracy on train set / val set 0 : 0.815625 / 0.575 (λ: 0.000400006,γ: 112.44444444444444)\n",
      "Accuracy on train set / val set 0 : 0.758125 / 0.59 (λ: 0.000600004,γ: 112.44444444444444)\n",
      "Accuracy on train set / val set 0 : 0.73375 / 0.5875 (λ: 0.0008000020000000001,γ: 112.44444444444444)\n",
      "Accuracy on train set / val set 0 : 0.715625 / 0.5675 (λ: 0.001,γ: 112.44444444444444)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5475 (λ: 1e-08,γ: 134.33333333333334)\n",
      "Accuracy on train set / val set 0 : 0.960625 / 0.595 (λ: 0.000200008,γ: 134.33333333333334)\n",
      "Accuracy on train set / val set 0 : 0.848125 / 0.57 (λ: 0.000400006,γ: 134.33333333333334)\n",
      "Accuracy on train set / val set 0 : 0.780625 / 0.5925 (λ: 0.000600004,γ: 134.33333333333334)\n",
      "Accuracy on train set / val set 0 : 0.750625 / 0.5825 (λ: 0.0008000020000000001,γ: 134.33333333333334)\n",
      "Accuracy on train set / val set 0 : 0.734375 / 0.58 (λ: 0.001,γ: 134.33333333333334)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 1e-08,γ: 156.22222222222223)\n",
      "Accuracy on train set / val set 0 : 0.971875 / 0.585 (λ: 0.000200008,γ: 156.22222222222223)\n",
      "Accuracy on train set / val set 0 : 0.87875 / 0.57 (λ: 0.000400006,γ: 156.22222222222223)\n",
      "Accuracy on train set / val set 0 : 0.8075 / 0.595 (λ: 0.000600004,γ: 156.22222222222223)\n",
      "Accuracy on train set / val set 0 : 0.77375 / 0.5875 (λ: 0.0008000020000000001,γ: 156.22222222222223)\n",
      "Accuracy on train set / val set 0 : 0.760625 / 0.5825 (λ: 0.001,γ: 156.22222222222223)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5625 (λ: 1e-08,γ: 178.11111111111111)\n",
      "Accuracy on train set / val set 0 : 0.981875 / 0.585 (λ: 0.000200008,γ: 178.11111111111111)\n",
      "Accuracy on train set / val set 0 : 0.9 / 0.5725 (λ: 0.000400006,γ: 178.11111111111111)\n",
      "Accuracy on train set / val set 0 : 0.83375 / 0.5925 (λ: 0.000600004,γ: 178.11111111111111)\n",
      "Accuracy on train set / val set 0 : 0.8 / 0.585 (λ: 0.0008000020000000001,γ: 178.11111111111111)\n",
      "Accuracy on train set / val set 0 : 0.785625 / 0.58 (λ: 0.001,γ: 178.11111111111111)\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.57 (λ: 1e-08,γ: 200.0)\n",
      "Accuracy on train set / val set 0 : 0.988125 / 0.595 (λ: 0.000200008,γ: 200.0)\n",
      "Accuracy on train set / val set 0 : 0.924375 / 0.575 (λ: 0.000400006,γ: 200.0)\n",
      "Accuracy on train set / val set 0 : 0.855625 / 0.5875 (λ: 0.000600004,γ: 200.0)\n",
      "Accuracy on train set / val set 0 : 0.83 / 0.5875 (λ: 0.0008000020000000001,γ: 200.0)\n",
      "Accuracy on train set / val set 0 : 0.815 / 0.5725 (λ: 0.001,γ: 200.0)\n"
     ]
    }
   ],
   "source": [
    "γ = 200\n",
    "λ = 1e-3\n",
    "\n",
    "gamma_list = np.linspace(3,γ,10, endpoint = True)\n",
    "lambda_list = np.linspace(1e-8, λ, 6, endpoint = True)\n",
    "settings = list(product(gamma_list,lambda_list))\n",
    "\n",
    "\n",
    "for j, tup in enumerate(settings):\n",
    "    \n",
    "    γ, λ = tup\n",
    "    \n",
    "    kernel = GaussianKernel(γ)\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    clf.fit(E_train, Y_train)\n",
    "    y_pred_train =clf.predict(E_train)\n",
    "    y_pred_val =clf.predict(E_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results):\n",
    "    \"\"\"\n",
    "    Save results in a csv file\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    - filename : string\n",
    "        Name of the file to be saved under the ``results`` folder\n",
    "        \n",
    "    - results : numpy.array\n",
    "        Resulting array (0 and 1's)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert filename.endswith(\".csv\"), \"this is not a csv extension!\"\n",
    "    # Convert results to int\n",
    "    results = results.astype(\"int\")\n",
    "    \n",
    "    with open(os.path.join(RESULT_DIR, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write header\n",
    "        writer.writerow([\"Id\", \"Bound\"]) \n",
    "        assert len(results) == 3000, \"There is not 3000 predictions\"\n",
    "        # Write results\n",
    "        for i in range(len(results)):\n",
    "            writer.writerow([i, results[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"results5.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
