{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    " #   writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "  #  writer.writerow([\"Id\", \"Bound\"])\n",
    "   # for i in range(3000):\n",
    "    #    writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR: A Simple Pattern Recognition Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPR:\n",
    "    \"\"\"\n",
    "    This class implements the Simple Pattern Recognition algorithm found in the Learning with Kernel books\n",
    "    \"\"\"\n",
    "    def __init__(self,c, kernel=False):\n",
    "        self.m0 = 0\n",
    "        self.m1 = 0\n",
    "        self.b = 0\n",
    "        self.c = c\n",
    "        self.kernel = kernel\n",
    "\n",
    "\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        Fitting phase\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        - X : numpy.ndarray\n",
    "            Data matrix\n",
    "            \n",
    "        - y : numpy.array\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = X\n",
    "        self.X0 = X[y == 0]\n",
    "        self.X1 = X[y == 1]\n",
    "        \n",
    "        self.m0 = len(self.X0)\n",
    "        self.m1 = len(self.X1)\n",
    "        \n",
    "        if self.kernel == False:\n",
    "            self.b = 1/2 * (1/(self.m0**2)*np.sum(self.X0.dot(self.X0.T)) - 1/(self.m1**2)*np.sum(self.X1.dot(self.X1.T)))\n",
    "        else:\n",
    "            # à changer\n",
    "            self.list0 = list(np.where(y==0)[0])\n",
    "            self.list1 = list(np.where(y==1)[0])\n",
    "            self.b = 1/2 * (1/(self.m0**2)*np.sum([self.kernel(self.X_train[i],self.X_train[j],self.c) for i in self.list0 for j in self.list0]) - (1/(self.m1**2))*np.sum([self.kernel(self.X_train[i],self.X_train[j],self.c) for i in self.list1 for j in self.list1]))\n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_pred = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if self.kernel == False:\n",
    "                val = 1 / self.m1 * np.sum(self.X1.dot(X[i])) - 1 / self.m0 * np.sum(self.X0.dot(X[i])) + self.b\n",
    "            else:\n",
    "                val = (1/self.m1*np.sum([kernel(self.X_train[k],X[i],self.c) for k in self.list1]) \n",
    "                       - 1/self.m0*np.sum([kernel(self.X_train[k],X[i],self.c) for k in self.list0])) + self.b\n",
    "            y_pred[i] = np.sign(val)/2 + 1/2\n",
    "        return y_pred    \n",
    "    \n",
    "    \n",
    "    def score(self, y, y_pred):\n",
    "        return np.sum([y == y_pred]) / len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_id, mat=True):\n",
    "    \n",
    "    X_train = list()\n",
    "    Y_train = list()\n",
    "    X_test = list()\n",
    "    \n",
    "    dic = FILES[file_id]\n",
    "    \n",
    "    if mat:\n",
    "        files = [dic[\"train_mat\"], dic[\"label\"], dic[\"test_mat\"]]\n",
    "    else:\n",
    "        files = [dic[\"train\"], dic[\"label\"], dic[\"test\"]]\n",
    "\n",
    "    for file, l in zip(files, [X_train, Y_train, X_test]):\n",
    "        with open(os.path.join(DATA_DIR, file), \"r\", newline=\"\") as csvfile:\n",
    "            if \"Y\" in file:\n",
    "                reader = csv.reader(csvfile, delimiter=\",\")\n",
    "                next(reader, None) # Skip the header\n",
    "                for row in reader:\n",
    "                    l.append(row[1])\n",
    "            else:\n",
    "                reader = csv.reader(csvfile, delimiter=\" \")\n",
    "                for row in reader:\n",
    "                    l.append(row)\n",
    "                \n",
    "    X_train = np.array(X_train).astype(\"float\")\n",
    "    Y_train = np.array(Y_train).astype(\"int\")\n",
    "    X_test = np.array(X_test).astype(\"float\")\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    index = np.random.permutation(len(X_train))\n",
    "    X_train = X_train[index]\n",
    "    Y_train = Y_train[index]\n",
    "    \n",
    "    return X_train, Y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol_kernel(x,y,c): #c=0\n",
    "    return (x.dot(y) + c)**2\n",
    "\n",
    "def gaussian_kernel(x,y, gamma): #c=100\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.563125 / 0.5175\n",
      "Accuracy on train set / val set 1 : 0.65125 / 0.605\n",
      "Accuracy on train set / val set 2 : 0.58625 / 0.6325\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros(3000)\n",
    "kernel = False\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SPR(0, kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Produit scalaire:**\n",
    "- Accuracy on train set / val set 0 : 0.563125 / 0.5175\n",
    "- Accuracy on train set / val set 1 : 0.65125 / 0.605\n",
    "- Accuracy on train set / val set 2 : 0.58625 / 0.6325\n",
    "\n",
    "**Noyau carré (<.,.>²):**\n",
    "\n",
    "\n",
    "**Noyau Gaussien:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 2 : 0.5735 / nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luc_b\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "len_val = 0\n",
    "len_train = n - len_val\n",
    "all_X_train = np.zeros((3*len_train,100))\n",
    "all_Y_train = np.zeros(3*len_train)\n",
    "all_X_val = np.zeros((3*len_val,100))\n",
    "all_Y_val = np.zeros(3*len_val)\n",
    "all_X_test = np.zeros((3000,100))\n",
    "\n",
    "\n",
    "kernel = False\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[len_train:]\n",
    "    Y_val = Y_train[len_train:]\n",
    "    X_train = X_train[:len_train]\n",
    "    Y_train = Y_train[:len_train]\n",
    "    all_X_train[i*len_train:i*len_train + len_train] = X_train\n",
    "    all_Y_train[i*len_train:i*len_train + len_train] = Y_train\n",
    "    all_X_val[i*len_val:i*len_val + len_val] = X_val\n",
    "    all_Y_val[i*len_val:i*len_val + len_val] = Y_val\n",
    "    all_X_test[i*1000:i*1000 + 1000] = X_test\n",
    "    \n",
    "clf = SPR(50, kernel)\n",
    "clf.fit(all_X_train, all_Y_train)\n",
    "y_pred_train =clf.predict(all_X_train)\n",
    "y_pred_val = clf.predict(all_X_val)\n",
    "y_pred_test = clf.predict(all_X_test)\n",
    "score_train = clf.score(y_pred_train, all_Y_train)\n",
    "score_val = clf.score(y_pred_val, all_Y_val)\n",
    "print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Produit scalaire:**\n",
    "- Accuracy on train set / val set 2 : 0.5741666666666667 / 0.5716666666666667\n",
    "\n",
    "\n",
    "**Noyau carré (<.,.>²):**\n",
    "  - Accuracy on train set / val set 2 : 0.5741666666666667 / 0.5716666666666667 $(c=0)$\n",
    "  \n",
    "**Noyau Gaussien:**\n",
    "- Accuracy on train set / val set 2 : 0.6504166666666666 / 0.57 $(\\gamma = 100)$\n",
    "- Accuracy on train set / val set 2 : 0.5702083333333333 / 0.5691666666666667 $(\\gamma = 10)$\n",
    "- Accuracy on train set / val set 2 : 0.5889583333333334 / 0.5725 $(\\gamma = 50)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \"\"\"\n",
    "    This class implements the Support Vector Machine algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, c, λ, kernel=False):\n",
    "        self.kernel = kernel\n",
    "        self.c = c\n",
    "        self.λ = λ\n",
    "        self.n = 0\n",
    "\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        Fitting phase\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        - X : numpy.ndarray\n",
    "            Data matrix\n",
    "            \n",
    "        - y : numpy.array\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X_train = X\n",
    "        \n",
    "        # Define the kernel matrix K\n",
    "        K = np.array([[kernel(x, y,self.c) for x in X_train] for y in X_train])\n",
    "        \n",
    "        # transpose Y_train to fit the optimization formulation\n",
    "        y = Y_train * 2 - 1\n",
    "        \n",
    "        # Use scipy.optimize to solve the problem\n",
    "        self.n = len(y)\n",
    "\n",
    "        # Define the loss function\n",
    "        f = lambda x: 1/2 * x.T.dot(K).dot(x) - y.T.dot(x) \n",
    "        \n",
    "        # Define the jacobian of the loss function\n",
    "        grad_f = lambda x: K.dot(x) - y\n",
    "\n",
    "        # Define the bounds (sequences of min, max) (This depends on the sign of Y_train)\n",
    "        bounds = [[0, y[i] / (2 * self.n * self.λ)] \n",
    "                  if y[i] > 0 \n",
    "                  else [y[i] / (2 * self.n * self.λ), 0] \n",
    "                  for i in range(self.n)]\n",
    "\n",
    "        # define initial point\n",
    "        x0 = np.zeros(self.n)\n",
    "        \n",
    "        # define number max iteration\n",
    "        opts = {\"maxiter\": 15000}\n",
    "        \n",
    "        # optimize\n",
    "        res = optimize.minimize(f, x0, jac=grad_f, bounds=bounds, method=\"L-BFGS-B\", options=opts)\n",
    "        \n",
    "        # save results\n",
    "        self.α = res[\"x\"]\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_pred = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if self.kernel == False:\n",
    "                return \"you have to define a kernel\"\n",
    "            else:\n",
    "                val = np.sum([self.α[j] * self.kernel(self.X_train[j], X[i], self.c) for j in range(self.n)])\n",
    "                \n",
    "            y_pred[i] = np.sign(val)/2 + 1/2\n",
    "            \n",
    "        return y_pred    \n",
    "    \n",
    "    \n",
    "    def score(self, y, y_pred):\n",
    "        return np.sum([y == y_pred]) / len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.680625 / 0.5625\n",
      "Accuracy on train set / val set 1 : 0.72 / 0.6\n",
      "Accuracy on train set / val set 2 : 0.70625 / 0.635\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "kernel = gaussian_kernel\n",
    "\n",
    "γ = 10\n",
    "λ = 1e-4\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVM(γ, λ, kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 1e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 1e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 1e-05,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5575 (λ: 5e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.745 (λ: 5e-05,γ: 300.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6325 (λ: 5e-05,γ: 300.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 1e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 1e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 1e-05,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.5775 (λ: 5e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7425 (λ: 5e-05,γ: 400.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6275 (λ: 5e-05,γ: 400.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 1e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 1e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 1e-05,γ: 500.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 5e-05,γ: 500.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5e-05,γ: 500.0)\n",
      "\n",
      "\n",
      "score : {0: 0.5775, 1: 0.745, 2: 0.6375}\n",
      "lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
      "gamma : {0: 400.0, 1: 300.0, 2: 500.0}\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 5e-5\n",
    "gamma_list = np.linspace(300,γ,3, endpoint = True)\n",
    "lambda_list = np.linspace(1e-5, λ, 2, endpoint = True)\n",
    "settings = list(product(gamma_list,lambda_list))\n",
    "best_score = {i: 0 for i in range(3)}\n",
    "best_lambda = {i: 0 for i in range(3)}\n",
    "best_gamma = {i: 0 for i in range(3)}\n",
    "\n",
    "for k, tup in enumerate(settings):\n",
    "    γ, λ = tup\n",
    "    \n",
    "    len_files = len(FILES)\n",
    "    for i in range(len_files):\n",
    "        X_train, Y_train, X_test = load_data(i)\n",
    "        X_val = X_train[1600:]\n",
    "        Y_val = Y_train[1600:]\n",
    "        X_train = X_train[:1600]\n",
    "        Y_train = Y_train[:1600]\n",
    "        clf = SVM(γ, λ, kernel)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        y_pred_train =clf.predict(X_train)\n",
    "        y_pred_val = clf.predict(X_val)\n",
    "        score_train = clf.score(y_pred_train, Y_train)\n",
    "        score_val = clf.score(y_pred_val, Y_val)\n",
    "        \n",
    "        if score_val > best_score[i]:\n",
    "            best_score[i] = score_val\n",
    "            best_lambda[i] = λ\n",
    "            best_gamma[i] = γ\n",
    "            \n",
    "        print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")\n",
    "        \n",
    "    print('\\n')\n",
    "        \n",
    "print(f\"score : {best_score}\")\n",
    "print(f\"lambda : {best_lambda}\")\n",
    "print(f\"gamma : {best_gamma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1er lancement:\n",
    "- score : {0: 0.6, 1: 0.6775, 2: 0.6425}\n",
    "- lambda : {0: 0.0002575, 1: 1e-05, 2: 0.000505}\n",
    "- gamma : {0: 77.5, 1: 100.0, 2: 32.5}\n",
    "\n",
    "2ème lancement:\n",
    "- score : {0: 0.61, 1: 0.7075, 2: 0.6425}\n",
    "- lambda : {0: 5.5e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 70.0, 1: 300.0, 2: 300.0}\n",
    "\n",
    "3ème lancement:\n",
    "- score : {0: 0.6075, 1: 0.73, 2: 0.66}\n",
    "- lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 350.0, 1: 400.0, 2: 500.0}\n",
    "\n",
    "4ème lancement:\n",
    "- score : {0: 0.59, 1: 0.73, 2: 0.6575}\n",
    "- lambda : {0: 5e-06, 1: 5e-06, 2: 5e-06}\n",
    "- gamma : {0: 400.0, 1: 400.0, 2: 400.0}\n",
    "\n",
    "5ème lancement ! :\n",
    "- score : {0: 0.59, 1: 0.73, 2: 0.6575}\n",
    "- lambda : {0: 5e-05, 1: 5e-05, 2: 5e-05}\n",
    "- gamma : {0: 400.0, 1: 400.0, 2: 400.0}\n",
    "\n",
    "6ème lancement (après shuffle):\n",
    "- score : {0: 0.5775, 1: 0.745, 2: 0.6375}\n",
    "- lambda : {0: 1e-05, 1: 1e-05, 2: 1e-05}\n",
    "- gamma : {0: 400.0, 1: 300.0, 2: 500.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose $\\gamma = 400$ and $\\lambda = 1e-5$ for the three sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luc_b\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / nan\n",
      "Accuracy on train set / val set 1 : 1.0 / nan\n",
      "Accuracy on train set / val set 2 : 1.0 / nan\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "kernel = gaussian_kernel\n",
    "\n",
    "γ = 400\n",
    "λ = 1e-5\n",
    "len_val =  0\n",
    "len_train = 2000 - len_val\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[len_train:]\n",
    "    Y_val = Y_train[len_train:]\n",
    "    X_train = X_train[:len_train]\n",
    "    Y_train = Y_train[:len_train]\n",
    "    clf = SVM(γ, λ, kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose different $\\gamma$ and $\\lambda$ for the three sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luc_b\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / nan\n",
      "Accuracy on train set / val set 1 : 1.0 / nan\n",
      "Accuracy on train set / val set 2 : 1.0 / nan\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "kernel = gaussian_kernel\n",
    "\n",
    "γ = [400, 300, 500]\n",
    "λ = [1e-5,1e-5,1e-5]\n",
    "len_val =  0\n",
    "len_train = 2000 - len_val\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    X_val = X_train[len_train:]\n",
    "    Y_val = Y_train[len_train:]\n",
    "    X_train = X_train[:len_train]\n",
    "    Y_train = Y_train[:len_train]\n",
    "    clf = SVM(γ[i], λ[i], kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    \n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "    results[i*1000:i*1000 + 1000] = y_pred_test\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results):\n",
    "    \"\"\"\n",
    "    Save results in a csv file\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    - filename : string\n",
    "        Name of the file to be saved under the ``results`` folder\n",
    "        \n",
    "    - results : numpy.array\n",
    "        Resulting array (0 and 1's)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert filename.endswith(\".csv\"), \"this is not a csv extension!\"\n",
    "    # Convert results to int\n",
    "    results = results.astype(\"int\")\n",
    "    \n",
    "    with open(os.path.join(RESULT_DIR, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write header\n",
    "        writer.writerow([\"Id\", \"Bound\"]) \n",
    "        assert len(results) == 3000, \"There is not 3000 predictions\"\n",
    "        # Write results\n",
    "        for i in range(len(results)):\n",
    "            writer.writerow([i, results[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"results5.csv\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
