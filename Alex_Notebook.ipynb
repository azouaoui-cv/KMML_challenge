{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders\n",
    "\n",
    "\n",
    "Now that we are done with the above, our goal is to implement SVM with Gaussian kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "from utils.data import load_data, save_results\n",
    "from utils.models import SVM, SPR\n",
    "from utils.kernels import GaussianKernel, LinearKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        writer.writerow([\"Id\", \"Bound\"])\n",
    "        for i in range(3000):\n",
    "            writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR\n",
    "\n",
    "* Simple Pattern Recognition algorithm with Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.99875 / 0.585 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.5775 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 5e-5\n",
    "kernel = GaussianKernel(γ)\n",
    "#kernel = LinearKernel()\n",
    "\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SPR(kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    clf = SPR()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    results[i*1000:i*1000 + 1000] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"test_results.csv\", results, result_dir=RESULT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with ``scikit-learn`` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 5e-5\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 5.0\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "print(f\"C: {1/(2 * n * λ)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.5725 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.5875 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVC(C=5.0, kernel=\"rbf\", gamma=500)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = np.sum([Y_train == y_pred_train]) / len(Y_train)\n",
    "    score_val = np.sum([Y_val == y_pred_val]) / len(Y_val)\n",
    "\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate and improve Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Diagnostic: introduce a tolerance parameter ``tol``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataset_idx, clf, k=5):\n",
    "    \"\"\"\n",
    "    Perform a k-fold cross-validation on a specific dataset\n",
    "    given a specific classifier\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    - dataset_idx : int\n",
    "        Dataset index to be called in the data loader\n",
    "        \n",
    "    - clf : object\n",
    "        Classifier object with methods:\n",
    "        . fit\n",
    "        . predict\n",
    "        . score\n",
    "        \n",
    "    - k : int\n",
    "        Number of folds\n",
    "    \n",
    "    Returns\n",
    "    -----------\n",
    "    - results : dictionary\n",
    "        Summary of the results\n",
    "        Note: the results can be display using\n",
    "        a pandas.DataFrame such as in:\n",
    "        ``pd.DataFrame(results)``\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    scores_val = list()\n",
    "    scores_train = list()\n",
    "    \n",
    "    # Load data\n",
    "    X_train, Y_train, X_test = load_data(dataset_idx, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    \n",
    "    n = len(X_train)\n",
    "    assert n == len(Y_train)\n",
    "    \n",
    "    # Divise the samples\n",
    "    bounds = [(i * (len(X_train) // k), (i+1) * (len(X_train) // k))\n",
    "              for i in range(k)]\n",
    "\n",
    "\n",
    "    # Loop through the divided samples\n",
    "    for bound in bounds:\n",
    "        lower, upper = bound\n",
    "        # Create index array for validation set\n",
    "        idx = np.arange(lower, upper)\n",
    "        not_idx = [i for i in range(n) if i not in idx]\n",
    "\n",
    "        # Populate current train and val sets\n",
    "        _X_val = X_train[idx]\n",
    "        _Y_val = Y_train[idx]\n",
    "        _X_train = X_train[not_idx]\n",
    "        _Y_train = Y_train[not_idx]\n",
    "\n",
    "        # Sanity checks\n",
    "        assert len(_X_train) == len(_Y_train)\n",
    "        assert len(_X_val) == len(_Y_val)\n",
    "        assert len(_X_train) == n - len(X_train) // k\n",
    "\n",
    "        # Fit the classifier on the current training set\n",
    "        clf.fit(_X_train, _Y_train)\n",
    "        # Compute the score\n",
    "        y_pred_train = clf.predict(_X_train)\n",
    "        y_pred_val = clf.predict(_X_val)\n",
    "        score_train = clf.score(y_pred_train, _Y_train)\n",
    "        score_val = clf.score(y_pred_val, _Y_val)\n",
    "\n",
    "        scores_val.append(score_val)\n",
    "        scores_train.append(score_train)\n",
    "\n",
    "\n",
    "   \n",
    "    # Format the results in a dictionary\n",
    "    # Compute the score average and standard deviation\n",
    "    results = {\"train_scores\": scores_train,\n",
    "               \"val_scores\": scores_val,\n",
    "               \"train_avg\": np.mean(scores_train),\n",
    "               \"val_avg\": np.mean(scores_val),\n",
    "               \"train_std\": np.std(scores_train),\n",
    "               \"val_std\": np.std(scores_val)}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_scores': [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'val_scores': [0.5625, 0.5675, 0.575, 0.6, 0.575],\n",
       " 'train_avg': 1.0,\n",
       " 'val_avg': 0.576,\n",
       " 'train_std': 0.0,\n",
       " 'val_std': 0.012903487900563932}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVM(_lambda=λ, kernel=kernel)\n",
    "\n",
    "cross_validation(0, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Grid Search using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.55 (λ: 5e-07,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.68 (λ: 5e-07,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.615 (λ: 5e-07,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.55 (λ: 2.875e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.68 (λ: 2.875e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.615 (λ: 2.875e-06,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.551 (λ: 5.2500000000000006e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.68 (λ: 5.2500000000000006e-06,γ: 50.0)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.615 (λ: 5.2500000000000006e-06,γ: 50.0)\n",
      "\n",
      "\n",
      "Accuracy on train set / val set 0 : 1.0 / 0.551 (λ: 7.625000000000001e-06,γ: 50.0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-91be696d9abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# cross validation (default: k=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mscore_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_avg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mscore_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_avg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-89068fdd1196>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(dataset_idx, clf, k)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Compute the score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0my_pred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_X_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mscore_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mscore_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Y_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MVA/Cours_S2/KMML/KMML_challenge/utils/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Compute the similarity matrix for faster prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_similarity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MVA/Cours_S2/KMML/KMML_challenge/utils/kernels.py\u001b[0m in \u001b[0;36mcompute_similarity_matrix\u001b[0;34m(self, Z, X)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mS0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Compute the similarity matrix using numpy vectorized functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "γ = 350\n",
    "λ = 1e-5\n",
    "gamma_list = np.linspace(50,γ,5, endpoint = True)\n",
    "lambda_list = np.linspace(5e-7, λ, 5, endpoint = True)\n",
    "\n",
    "settings = list(product(gamma_list,lambda_list))\n",
    "\n",
    "best_score = {i: 0 for i in range(3)}\n",
    "best_lambda = {i: 0 for i in range(3)}\n",
    "best_gamma = {i: 0 for i in range(3)}\n",
    "\n",
    "for k, tup in enumerate(settings):\n",
    "    \n",
    "    γ, λ = tup\n",
    "    kernel = GaussianKernel(γ)\n",
    "    \n",
    "    len_files = len(FILES)\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    \n",
    "    for i in range(len_files):\n",
    "        # cross validation (default: k=5)\n",
    "        results = cross_validation(i, clf)\n",
    "        score_train = results[\"train_avg\"]\n",
    "        score_val = results[\"val_avg\"]\n",
    "        print(f\"Accuracy on train set / val set {i} : {round(score_train, 3)} / {round(score_val, 3)} (λ: {λ},γ: {γ})\")\n",
    "        \n",
    "        if score_val > best_score[i]:\n",
    "            best_score[i] = score_val\n",
    "            best_lambda[i] = λ\n",
    "            best_gamma[i] = γ\n",
    "        \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-padding implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = {'A': [1.,0.,0.,0.],\n",
    "            'C': [0.,1.,0.,0.],\n",
    "            'G': [0.,0.,1.,0.],\n",
    "            'T': [0.,0.,0.,1.],\n",
    "            'Z': [0.,0.,0.,0.]} # used in zero-padding\n",
    "\n",
    "def P(i, seq, k, zero_padding=True):\n",
    "    \"\"\"\n",
    "    Compute the a k_mers at a given position in a nucleotides sequence\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    - i : int\n",
    "        Position in the sequence\n",
    "        \n",
    "    - k : int\n",
    "        Size of k-mer to be returned\n",
    "        \n",
    "    - seq : str\n",
    "        Sequence of nucleotides\n",
    "        \n",
    "    - zero_padding : boolean (optional)\n",
    "        Whether to use zero-padding on the sequence edges\n",
    "        Default: True\n",
    "        \n",
    "    Returns\n",
    "    -----------\n",
    "    - L : numpy.array\n",
    "        One-hot encoding of the string sequence\n",
    "        \n",
    "    - not_in : boolean\n",
    "        Whether the k-mer was computed on the sequence edges\n",
    "        Always set to False when using zero-padding\n",
    "    \"\"\"\n",
    "    # Setup\n",
    "    not_in = True\n",
    "    if zero_padding:\n",
    "        not_in = False\n",
    "    \n",
    "    # lower edge\n",
    "    if i-(k+1)//2 + 1 < 0:\n",
    "        # Use heading zero padding here\n",
    "        n_zeros = abs(i - (k+1) // 2 + 1)\n",
    "        k_mer_i = 'Z'*n_zeros + seq[:  i + (k+2)//2]\n",
    "    # upper edge\n",
    "    elif i + (k+2)//2 > len(seq):\n",
    "        # Use trailing zero padding here\n",
    "        n_zeros = i + (k+2) // 2 - len(seq)\n",
    "        k_mer_i = seq[i - (k+1)//2 + 1:] + 'Z'*n_zeros\n",
    "    # in the middle\n",
    "    else:\n",
    "        k_mer_i = seq[i-(k+1)//2 + 1 :  i + (k+2)//2]\n",
    "        not_in = False\n",
    "        \n",
    "    # concatenate one hot encoding\n",
    "    L = []\n",
    "    for c in k_mer_i:\n",
    "        L += ENCODING[c]\n",
    "    \n",
    "    # Sanity check\n",
    "    assert len(L) == 4 * k\n",
    "    \n",
    "    # Convert to array and return\n",
    "    return np.array(L), not_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: CKN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km",
   "language": "python",
   "name": "km"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
