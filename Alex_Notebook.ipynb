{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders\n",
    "\n",
    "\n",
    "Now that we are done with the above, our goal is to implement SVM with Gaussian kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    writer.writerow([\"Id\", \"Bound\"])\n",
    "    for i in range(3000):\n",
    "        writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPR:\n",
    "    \"\"\"\n",
    "    This class implements the Simple Pattern Recognition algorithm found in the Learning with Kernel books\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.m0 = 0\n",
    "        self.m1 = 0\n",
    "        self.b = 0\n",
    "\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        Fitting phase\n",
    "        \n",
    "        Parameters\n",
    "        ------------\n",
    "        - X : numpy.ndarray\n",
    "            Data matrix\n",
    "            \n",
    "        - y : numpy.array\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X0 = X[y == 0]\n",
    "        self.X1 = X[y == 1]\n",
    "        \n",
    "        self.m0 = len(self.X0)\n",
    "        self.m1 = len(self.X1)\n",
    "        \n",
    "        self.b = 1/2 * (1/(self.m0**2)*np.sum(self.X0.dot(self.X0.T)) - 1/(self.m1**2)*np.sum(self.X1.dot(self.X1.T)))\n",
    "        \n",
    "        #self.b = 1/2 * (1/(self.m0**2)*np.sum([kernel(self.X_train[i],self.X_train[j]) for i in self.list0 for j in self.list0]) - 1/(self.m1)**2*np.sum([kernel(self.X_train[i],self.X_train[j]) for i in self.list1 for j in self.list1]))\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        y_pred = np.zeros(len(X))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            val = 1 / self.m1 * np.sum(self.X1.dot(X[i])) - 1 / self.m0 * np.sum(self.X0.dot(X[i])) + self.b\n",
    "            #val = 1/self.m1*np.sum([kernel(self.X_train[k],X[i]) for k in self.list1]) - 1/self.m0*np.sum([kernel(self.X_train[k],X[i]) for k in self.list0]) + self.b\n",
    "            y_pred[i] = np.sign(val)/2 + 1/2\n",
    "        return y_pred\n",
    "    \n",
    "        #val = 1 / self.m0 * np.sum(self.X0.dot(X.T)) + 1 / self.m1 * np.sum(self.X1.dot(X.T)) + self.b\n",
    "        #y_pred = np.sign(val) / 2 + 1/2\n",
    "        #return y_pred.astype(\"int\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def score(self, y, y_pred):\n",
    "        return np.sum(y[y == y_pred]) / len(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_id, mat=True):\n",
    "    \n",
    "    X_train = list()\n",
    "    Y_train = list()\n",
    "    X_test = list()\n",
    "    \n",
    "    dic = FILES[file_id]\n",
    "    \n",
    "    if mat:\n",
    "        files = [dic[\"train_mat\"], dic[\"label\"], dic[\"test_mat\"]]\n",
    "    else:\n",
    "        files = [dic[\"train\"], dic[\"label\"], dic[\"test\"]]\n",
    "\n",
    "    for file, l in zip(files, [X_train, Y_train, X_test]):\n",
    "        with open(os.path.join(DATA_DIR, file), \"r\", newline=\"\") as csvfile:\n",
    "            if \"Y\" in file:\n",
    "                reader = csv.reader(csvfile, delimiter=\",\")\n",
    "                next(reader, None) # Skip the header\n",
    "                for row in reader:\n",
    "                    l.append(row[1])\n",
    "            else:\n",
    "                reader = csv.reader(csvfile, delimiter=\" \")\n",
    "                for row in reader:\n",
    "                    l.append(row)\n",
    "                \n",
    "    X_train = np.array(X_train).astype(\"float\")\n",
    "    Y_train = np.array(Y_train).astype(\"int\")\n",
    "    X_test = np.array(X_test).astype(\"float\")\n",
    "    \n",
    "    return X_train, Y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i)\n",
    "    clf = SPR()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    results[i*1000:i*1000 + 1000] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(filename, results):\n",
    "    \"\"\"\n",
    "    Save results in a csv file\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    - filename : string\n",
    "        Name of the file to be saved under the ``results`` folder\n",
    "        \n",
    "    - results : numpy.array\n",
    "        Resulting array (0 and 1's)\n",
    "    \"\"\"\n",
    "    \n",
    "    assert filename.endswith(\".csv\"), \"this is not a csv extension!\"\n",
    "    # Convert results to int\n",
    "    results = results.astype(\"int\")\n",
    "    \n",
    "    with open(os.path.join(RESULT_DIR, filename), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        # Write header\n",
    "        writer.writerow([\"Id\", \"Bound\"]) \n",
    "        assert len(results) == 3000, \"There is not 3000 predictions\"\n",
    "        # Write results\n",
    "        for i in range(len(results)):\n",
    "                writer.writerow([i, results[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"test_results.csv\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_kernel(x,y,c): #c=0\n",
    "    return (x.dot(y) + c)**2\n",
    "\n",
    "# Define the Gaussian Kernel (or Radial Basis Function)\n",
    "\n",
    "def rbf_kernel(x,y, gamma=10): #c=100\n",
    "    return np.exp(-gamma*np.linalg.norm(x-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load some data\n",
    "X_train, Y_train, X_test = load_data(2)\n",
    "\n",
    "# Define the kernel to use\n",
    "kernel = rbf_kernel\n",
    "\n",
    "# Define the kernel matrix K\n",
    "K = np.array([[kernel(x, y) for x in X_train]\n",
    "              for y in X_train])\n",
    "\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose Y_train to fit the optimization formulation\n",
    "y = Y_train * 2 - 1\n",
    "\n",
    "###########################################\n",
    "# Use scipy.optimize to solve the problem #\n",
    "###########################################\n",
    "\n",
    "n = len(y)\n",
    "# Define λ\n",
    "#λ = 1 / n\n",
    "λ = 1 / 10000\n",
    "\n",
    "# Define the loss function\n",
    "f = lambda x: 1/2 * x.T.dot(K).dot(x) - y.T.dot(x)    \n",
    "# Define the jacobian of the loss function\n",
    "grad_f = lambda x: K.dot(x) - y\n",
    "\n",
    "# Define the bounds (sequences of min, max)\n",
    "# This depends on the sign of Y_train\n",
    "bounds = [[0, y[i] / (2 * n * λ)] \n",
    "          if y[i] > 0\n",
    "          else [y[i] / (2 * n * λ), 0]\n",
    "          for i in range(n)]\n",
    "\n",
    "\n",
    "x0 = np.zeros(n)\n",
    "opts = {\"maxiter\": 15000}\n",
    "res = optimize.minimize(f, x0, jac=grad_f, bounds=bounds, method=\"L-BFGS-B\", options=opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the results to the test data points\n",
    "n_test = len(X_test)\n",
    "y_predict = np.zeros(n_test)\n",
    "\n",
    "α = res[\"x\"]\n",
    "\n",
    "for i in range(n_test):\n",
    "    y_predict[i] = np.sign(np.sum([α[j] * kernel(X_train[j], X_test[i]) for j in range(n)])) / 2 + 1/2\n",
    "    \n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([657, 343]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_predict, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "α = res[\"x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([751,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1, 344,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "         1,   1,   1,   1,   1,   1, 758])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, c = np.unique(α, return_counts=True)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.5       , -2.49744715, -2.48645214, ...,  2.48677423,\n",
       "        2.48958713,  2.5       ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([344])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#u[u == 0]\n",
    "c[u == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict = np.zeros(n)\n",
    "\n",
    "α = res[\"x\"]\n",
    "\n",
    "for i in range(n):\n",
    "    y_train_predict[i] = np.sign(np.sum([α[j] * kernel(X_train[j], X_train[i]) for j in range(n)])) / 2 + 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6865"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([Y_train == y_train_predict]) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km",
   "language": "python",
   "name": "km"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
