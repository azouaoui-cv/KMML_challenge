{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Scratchbook\n",
    "\n",
    "* This notebook explores methods for the Kernel Methods for Machine Learning Kaggle [challenge](https://www.kaggle.com/c/kernel-methods-for-machine-learning-2018-2019/data).\n",
    "\n",
    "* Note that this is a binary classification challenge.\n",
    "\n",
    "Our first goal is to implement two baseline methods:\n",
    "1. Random classification\n",
    "2. All instances are 0s (Doing so we get an idea of the proportion of 0's in the public test set)\n",
    "3. Implement the Simple Pattern Recognition Algorithm (SPR) from Learning with Kernels \n",
    "\n",
    "Before that, we have to implement some data loaders\n",
    "\n",
    "\n",
    "Now that we are done with the above, our goal is to implement SVM with Gaussian kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from utils.data import load_data, save_results\n",
    "from utils.models import SVM, SPR\n",
    "from utils.kernels import GaussianKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_DIR = os.path.join(CWD, \"data\")\n",
    "RESULT_DIR = os.path.join(CWD, \"results\")\n",
    "\n",
    "FILES = {0: {\"train_mat\": \"Xtr0_mat100.csv\",\n",
    "             \"train\": \"Xtr0.csv\",\n",
    "             \"test_mat\": \"Xte0_mat100.csv\",\n",
    "             \"test\": \"Xte0.csv\",\n",
    "             \"label\": \"Ytr0.csv\"},\n",
    "         1: {\"train_mat\": \"Xtr1_mat100.csv\",\n",
    "             \"train\": \"Xtr1.csv\",\n",
    "             \"test_mat\": \"Xte1_mat100.csv\",\n",
    "             \"test\": \"Xte1.csv\",\n",
    "             \"label\": \"Ytr1.csv\"},\n",
    "         2: {\"train_mat\": \"Xtr2_mat100.csv\",\n",
    "             \"train\": \"Xtr2.csv\",\n",
    "             \"test_mat\": \"Xte2_mat100.csv\",\n",
    "             \"test\": \"Xte2.csv\",\n",
    "             \"label\": \"Ytr2.csv\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(os.path.join(RESULT_DIR, \"results.csv\"), 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "\n",
    "        writer.writerow([\"Id\", \"Bound\"])\n",
    "        for i in range(3000):\n",
    "            writer.writerow([i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* We get 0.51266 which means that the dataset is pretty balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPR\n",
    "\n",
    "* Simple Pattern Recognition algorithm with Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 0.99875 / 0.585 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.5775 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 5e-5\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SPR(kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test on the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(3000)\n",
    "\n",
    "for i in range(len(FILES)):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    clf = SPR()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    results[i*1000:i*1000 + 1000] = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the save results function\n",
    "save_results(\"test_results.csv\", results, result_dir=RESULT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with ``scikit-learn`` implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.575 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.7275 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.6375 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "γ = 500\n",
    "λ = 5e-5\n",
    "kernel = GaussianKernel(γ)\n",
    "\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVM(_lambda=λ, kernel=kernel)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train =clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = clf.score(y_pred_train, Y_train)\n",
    "    score_val = clf.score(y_pred_val, Y_val)\n",
    "\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 5.0\n"
     ]
    }
   ],
   "source": [
    "n = 2000\n",
    "print(f\"C: {1/(2 * n * λ)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set / val set 0 : 1.0 / 0.5725 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 1 : 1.0 / 0.705 (λ: 5e-05,γ: 500)\n",
      "Accuracy on train set / val set 2 : 1.0 / 0.5875 (λ: 5e-05,γ: 500)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "len_files = len(FILES)\n",
    "for i in range(len_files):\n",
    "    X_train, Y_train, X_test = load_data(i, data_dir=DATA_DIR, files_dict=FILES)\n",
    "    X_val = X_train[1600:]\n",
    "    Y_val = Y_train[1600:]\n",
    "    X_train = X_train[:1600]\n",
    "    Y_train = Y_train[:1600]\n",
    "    clf = SVC(C=5.0, kernel=\"rbf\", gamma=500)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    score_train = np.sum([Y_train == y_pred_train]) / len(Y_train)\n",
    "    score_val = np.sum([Y_val == y_pred_val]) / len(Y_val)\n",
    "\n",
    "    print(f\"Accuracy on train set / val set {i} : {score_train} / {score_val} (λ: {λ},γ: {γ})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km",
   "language": "python",
   "name": "km"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
